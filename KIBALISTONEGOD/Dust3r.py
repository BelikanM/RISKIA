# type: ignore
import streamlit as st
import torch
from pathlib import Path
import tempfile
import os
import sys
import json
sys.path.append(os.path.join(os.path.dirname(__file__), 'dust3r'))
import time
import uuid
from PIL import Image
from PIL.ExifTags import TAGS, GPSTAGS
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import open3d as o3d  # pip install open3d
import zipfile
import pandas as pd
import io
import pickle
import subprocess
import shutil  # Ajout pour check Blender
from sklearn.cluster import KMeans
from sklearn.neighbors import NearestNeighbors  # Fallback pour FAISS
from transformers import CLIPProcessor, CLIPModel
try:
    import psutil  # pip install psutil pour monitoring CPU
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    psutil = None  # type: ignore

try:
    import pynvml  # pip install pynvml pour monitoring GPU (NVIDIA)
    pynvml.nvmlInit()
    NVML_AVAILABLE = True
except ImportError:
    NVML_AVAILABLE = False

try:
    import laspy  # type: ignore
    LAS_AVAILABLE = True
except ImportError:
    LAS_AVAILABLE = False

# Py4DGeo-inspired 4D Change Detection imports
try:
    import scipy.spatial  # Pour les calculs de distance
    import scipy.stats    # Pour les statistiques
    import matplotlib.pyplot as plt  # Pour les graphiques de distribution
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False

import gc

try:
    from texture_pbr_analyzer import TexturePBRAnalyzer, analyze_images_for_pbr
    PBR_ANALYZER_AVAILABLE = True
except ImportError:
    PBR_ANALYZER_AVAILABLE = False
    print("‚ö†Ô∏è Module texture_pbr_analyzer non disponible")

# Import du moteur VFX intelligent
try:
    from intelligent_vfx_engine import IntelligentVFXEngine, VFXParameters, MaterialType, apply_intelligent_vfx
    VFX_ENGINE_AVAILABLE = True
except ImportError:
    VFX_ENGINE_AVAILABLE = False
    print("‚ö†Ô∏è Module intelligent_vfx_engine non disponible")

# Import du mapper PBR automatique
try:
    from auto_pbr_mapper import AutoPBRMapper, generate_complete_pbr_pipeline
    AUTO_PBR_MAPPER_AVAILABLE = True
except ImportError:
    AUTO_PBR_MAPPER_AVAILABLE = False
    print("‚ö†Ô∏è Module auto_pbr_mapper non disponible")

# Import du gestionnaire de t√©l√©chargement de textures
try:
    from texture_download_manager import TextureDownloadManager
    TEXTURE_MANAGER_AVAILABLE = True
except ImportError:
    TEXTURE_MANAGER_AVAILABLE = False
    print("‚ö†Ô∏è Module texture_download_manager non disponible")

# Imports sp√©cifiques √† DUSt3R (assurez-vous d'avoir install√© : pip install git+https://github.com/naver/dust3r.git)
from dust3r.inference import inference
from dust3r.model import AsymmetricCroCo3DStereo
from dust3r.utils.image import load_images as dust3r_load_images
from dust3r.image_pairs import make_pairs
from dust3r.cloud_opt import global_aligner, GlobalAlignerMode
from dust3r.utils.geometry import xy_grid

# Initialize variables to avoid Pylance possibly unbound errors
batch_size = 1
niter_align = 300
lr_align = 0.01
threshold_conf = 0.5
max_points_per_view = 20000
scale_factor = 1.0
generate_mesh = False
mesh_method = "Poisson"
poisson_depth = 10
ball_pivoting_max_radius = 0.02
advanced_blender = False
export_obj = False
auto_smooth_normals = True
multi_view_blender = False
basic_uv_mapping = False
save_blend_file = False
show_hull = True
wireframe_overlay = False
wireframe_thickness = 1.0
show_uv_checker = False
subdivision_level = 0
show_normals = False
show_topology_info = False
texture_zip = None
process_btn = False

models = {}  # Global dict for models to allow manual freeing

# Tentative d'import FAISS avec fallback
try:
    import faiss
    FAISS_AVAILABLE = True
except ImportError:
    FAISS_AVAILABLE = False
    st.warning("FAISS non disponible ; fallback sur scikit-learn NearestNeighbors pour recherche de similarit√©.")

os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"

# Fonction de nettoyage du session state pour √©viter les conflits DOM
def clear_session_state():
    """Nettoie le session state pour √©viter les conflits d'√©l√©ments DOM dupliqu√©s"""
    keys_to_clear = [
        'advanced_denoising_params', 'mesh_params', 'vfx_params',
        'pbr_analysis_results', 'scene_graph_data', 'texture_analysis'
    ]
    for key in keys_to_clear:
        if key in st.session_state:
            del st.session_state[key]

# Nettoyer le session state au d√©marrage pour √©viter les conflits
clear_session_state()

# Fonction pour g√©or√©f√©rencement
def gps_to_local_coords(lat, lon, alt, ref_lat, ref_lon, ref_alt):
    """
    Convertit GPS en coordonn√©es locales (m√®tres) par rapport √† un point de r√©f√©rence.
    Approximation pour petites zones.
    """
    import math
    # Rayon terrestre approximatif
    R = 6371000  # m√®tres
    # Conversion degr√©s en radians
    lat_rad = math.radians(lat)
    lon_rad = math.radians(lon)
    ref_lat_rad = math.radians(ref_lat)
    ref_lon_rad = math.radians(ref_lon)
    
    # Diff√©rences
    dlat = lat - ref_lat
    dlon = lon - ref_lon
    
    # Conversion en m√®tres
    x = dlon * (math.pi / 180) * R * math.cos(ref_lat_rad)  # Est-Ouest
    y = dlat * (math.pi / 180) * R  # Nord-Sud
    z = alt - ref_alt  # Altitude
    
    return x, y, z

def get_gps_from_exif(img_path):
    """
    Extrait les coordonn√©es GPS depuis l'EXIF d'une image.
    """
    try:
        img = Image.open(img_path)
        exif_data = img.getexif()
        if not exif_data:
            return None
        
        gps_info = exif_data.get(34853)  # GPSInfo tag
        if not gps_info:
            return None
        
        def convert_to_degrees(value):
            d, m, s = value
            return d + (m / 60.0) + (s / 3600.0)
        
        lat = convert_to_degrees(gps_info[2])
        if gps_info[1] == 'S':
            lat = -lat
        lon = convert_to_degrees(gps_info[4])
        if gps_info[3] == 'W':
            lon = -lon
        alt = gps_info.get(6, 0) if gps_info.get(6) else 0
        
        return lat, lon, alt
    except:
        return None

def export_to_las(merged_pts3d, merged_colors, filename="pointcloud.las"):
    """
    Exporte le nuage de points en format LAS avec couleurs.
    """
    if not LAS_AVAILABLE:
        st.error("laspy non install√©. Installez avec: pip install laspy")
        return None
    
    # Cr√©er un fichier LAS
    header = laspy.LasHeader(point_format=3, version="1.2")  # type: ignore
    header.add_extra_dim(laspy.ExtraBytesParams(name="red", type=np.uint16))  # type: ignore
    header.add_extra_dim(laspy.ExtraBytesParams(name="green", type=np.uint16))  # type: ignore
    header.add_extra_dim(laspy.ExtraBytesParams(name="blue", type=np.uint16))  # type: ignore
    
    las = laspy.LasData(header)  # type: ignore
    las.x = merged_pts3d[:, 0]  # type: ignore
    las.y = merged_pts3d[:, 1]  # type: ignore
    las.z = merged_pts3d[:, 2]  # type: ignore
    
    # Couleurs en uint16 (0-65535)
    las.red = (merged_colors[:, 0] * 65535).astype(np.uint16)  # type: ignore
    las.green = (merged_colors[:, 1] * 65535).astype(np.uint16)  # type: ignore
    las.blue = (merged_colors[:, 2] * 65535).astype(np.uint16)  # type: ignore
    
    # Sauvegarder en bytes pour download
    with io.BytesIO() as buffer:
        las.write(buffer)  # type: ignore
        buffer.seek(0)
        return buffer.read()

def ransac_plane_detection(pcd, distance_threshold=0.02, ransac_n=3, num_iterations=1000):
    """
    D√©tection de plan avec RANSAC utilisant Open3D (scientifique et robuste).
    """
    plane_model, inliers = pcd.segment_plane(distance_threshold=distance_threshold,
                                             ransac_n=ransac_n,
                                             num_iterations=num_iterations)
    return plane_model, inliers

def ransac_cylinder_detection(points, distance_threshold=0.05, max_iterations=1000):
    """
    D√©tection de cylindre avec RANSAC personnalis√© (utilisant numpy pour calculs scientifiques).
    """
    best_model = None
    best_inliers = []
    n_points = len(points)
    
    for _ in range(max_iterations):
        # √âchantillonner 2 points pour d√©finir l'axe, 1 point pour le rayon
        sample_indices = np.random.choice(n_points, 3, replace=False)
        sample_points = points[sample_indices]
        
        # Calculer l'axe (vecteur entre les 2 premiers points)
        axis = sample_points[1] - sample_points[0]
        axis = axis / np.linalg.norm(axis)  # Normaliser
        
        # Point sur l'axe (milieu)
        center = (sample_points[0] + sample_points[1]) / 2
        
        # Rayon : distance du 3√®me point √† l'axe
        vec_to_point = sample_points[2] - center
        radius = np.abs(np.dot(vec_to_point, axis))
        
        # Calculer inliers : points dont la distance √† l'axe est proche du rayon
        inliers = []
        for i, point in enumerate(points):
            vec = point - center
            dist_to_axis = np.linalg.norm(vec - np.dot(vec, axis) * axis)
            if np.abs(dist_to_axis - radius) < distance_threshold:
                inliers.append(i)
        
        if len(inliers) > len(best_inliers):
            best_inliers = inliers
            best_model = {"axis": axis, "center": center, "radius": radius}
    
    return best_model, best_inliers

def ransac_sphere_detection(points, distance_threshold=0.05, max_iterations=1000):
    """
    D√©tection de sph√®re avec RANSAC personnalis√© (calculs scientifiques avec numpy).
    """
    best_model = None
    best_inliers = []
    n_points = len(points)
    
    for _ in range(max_iterations):
        # √âchantillonner 4 points pour d√©finir la sph√®re
        sample_indices = np.random.choice(n_points, 4, replace=False)
        sample_points = points[sample_indices]
        
        # Calculer le centre et rayon √† partir de 4 points (m√©thode d√©terministe)
        # Utiliser la formule pour 4 points non coplanaires
        try:
            # Matrice pour r√©soudre le syst√®me
            A = np.array([
                [sample_points[0][0], sample_points[0][1], sample_points[0][2], 1],
                [sample_points[1][0], sample_points[1][1], sample_points[1][2], 1],
                [sample_points[2][0], sample_points[2][1], sample_points[2][2], 1],
                [sample_points[3][0], sample_points[3][1], sample_points[3][2], 1]
            ])
            b = np.array([
                -np.sum(sample_points[0]**2),
                -np.sum(sample_points[1]**2),
                -np.sum(sample_points[2]**2),
                -np.sum(sample_points[3]**2)
            ])
            x = np.linalg.solve(A, b)
            center = -0.5 * x[:3]
            radius = np.sqrt(np.sum(center**2) - x[3])
            
            # Calculer inliers
            inliers = []
            for i, point in enumerate(points):
                dist = np.linalg.norm(point - center)
                if np.abs(dist - radius) < distance_threshold:
                    inliers.append(i)
            
            if len(inliers) > len(best_inliers):
                best_inliers = inliers
                best_model = {"center": center, "radius": radius}
        except np.linalg.LinAlgError:
            continue  # Points coplanaires, ignorer
    
    return best_model, best_inliers

def setup_ui():
    """Configure l'interface utilisateur principale"""
    st.title("üì∏ Application de Photogramm√©trie Compl√®te SETRAF GABON d√©velopp√©e par NYUNDU FRANCIS ARNAUD")
    st.markdown("---")

    # Bouton de r√©initialisation du session state pour √©viter les erreurs DOM
    col_reset, col_info = st.columns([1, 3])
    with col_reset:
        if st.button("üîÑ R√©initialiser l'interface", help="Nettoie le session state pour r√©soudre les erreurs d'affichage"):
            clear_session_state()
            st.rerun()

    with col_info:
        st.markdown("Cette application permet de charger plusieurs images, d'effectuer une reconstruction 3D dense √† partir de paires d'images en utilisant le mod√®le DUSt3R ou MapAnything, et de visualiser le nuage de points align√© globalement avec textures r√©alistes et option de maillage complet ultra-r√©aliste.")

    # Monitoring et s√©lection device
    use_gpu = st.sidebar.checkbox("Utiliser GPU (d√©sactiver si surchauffe)", value=True, help="D√©sactivez pour forcer CPU en cas de surchauffe GPU.")
    device = 'cuda' if use_gpu and torch.cuda.is_available() else 'cpu'
    st.sidebar.info(f"**P√©riph√©rique utilis√© :** {device.upper()}")

    return device

def perform_ransac_analysis(pcd, enable_auto_ransac, ransac_auto_threshold, ransac_auto_iterations):
    """Effectue l'analyse RANSAC automatique"""
    detected_shapes = {}
    if enable_auto_ransac:
        st.info("üî¨ Analyse g√©om√©trique automatique en cours...")
        points = np.asarray(pcd.points)
        modified_colors = np.array(pcd.colors)

        # D√©tection plan
        try:
            plane_model, plane_inliers = ransac_plane_detection(pcd, distance_threshold=ransac_auto_threshold,
                                                               num_iterations=ransac_auto_iterations)
            if len(plane_inliers) > len(points) * 0.1:  # Au moins 10% des points
                [a, b, c, d] = plane_model
                detected_shapes['plan'] = {"model": [a, b, c, d], "inliers": len(plane_inliers)}
                # Colorer inliers en rouge
                modified_colors[plane_inliers] = [1.0, 0.0, 0.0]  # Rouge
                st.success(f"Plan d√©tect√© automatiquement : {a:.3f}x + {b:.3f}y + {c:.3f}z + {d:.3f} = 0 ({len(plane_inliers)} points)")
        except:
            pass

        # D√©tection cylindre
        try:
            cyl_model, cyl_inliers = ransac_cylinder_detection(points, distance_threshold=ransac_auto_threshold,
                                                              max_iterations=ransac_auto_iterations)
            if cyl_model and len(cyl_inliers) > len(points) * 0.05:  # Au moins 5%
                detected_shapes['cylindre'] = {"model": cyl_model, "inliers": len(cyl_inliers)}
                # Colorer inliers en vert
                modified_colors[cyl_inliers] = [0.0, 1.0, 0.0]  # Vert
                st.success(f"Cylindre d√©tect√© : Rayon {cyl_model['radius']:.3f} ({len(cyl_inliers)} points)")
        except:
            pass

        # D√©tection sph√®re
        try:
            sph_model, sph_inliers = ransac_sphere_detection(points, distance_threshold=ransac_auto_threshold,
                                                            max_iterations=ransac_auto_iterations)
            if sph_model and len(sph_inliers) > len(points) * 0.05:
                detected_shapes['sphere'] = {"model": sph_model, "inliers": len(sph_inliers)}
                # Colorer inliers en bleu
                modified_colors[sph_inliers] = [0.0, 0.0, 1.0]  # Bleu
                st.success(f"Sph√®re d√©tect√©e : Rayon {sph_model['radius']:.3f} ({len(sph_inliers)} points)")
        except:
            pass

        # Mettre √† jour les couleurs du nuage
        pcd.colors = o3d.utility.Vector3dVector(modified_colors)
        st.info("üé® Nuage color√© automatiquement : Rouge=Plans, Vert=Cylindres, Bleu=Sph√®res, Original=Autres")

    return detected_shapes

def apply_realtime_downsampling_pipeline(pcd, target_points=100000, strategy='auto', preserve_colors=True, preserve_normals=False):
    """
    Pipeline de downsampling temps r√©el ultra-rapide inspir√© par Sohail Saifi.
    
    Args:
        pcd: Point cloud Open3D
        target_points: Nombre de points cible souhait√©
        strategy: Strat√©gie ('auto', 'speed', 'quality', 'balanced')
        preserve_colors: Pr√©server les informations de couleur
        preserve_normals: Pr√©server les normales de surface
        
    Returns:
        Point cloud downsampl√©
    """
    import time
    start_time = time.time()
    
    # Nombre de points original
    original_points = len(np.asarray(pcd.points))
    
    # Analyse adaptative du volume
    if strategy == 'auto':
        if original_points > 10000000:  # >10M points
            strategy = 'speed'
        elif original_points > 1000000:  # >1M points
            strategy = 'balanced'
        else:  # <1M points
            strategy = 'quality'
    
    # √âtape 1: Pr√©-downsampling par voxels pour volumes massifs
    if original_points > 5000000:  # >5M points
        # Calcul adaptatif de la taille de voxel
        points = np.asarray(pcd.points)
        bbox = points.max(axis=0) - points.min(axis=0)
        volume = np.prod(bbox)
        voxel_size = (volume / target_points) ** (1/3) * 0.1  # Ajustement adaptatif
        
        # Downsampling voxel grid
        pcd = pcd.voxel_down_sample(voxel_size=voxel_size)
        current_points = len(np.asarray(pcd.points))
        
        # Si encore trop de points, r√©duire davantage
        if current_points > target_points * 2:
            voxel_size *= 1.5
            pcd = pcd.voxel_down_sample(voxel_size=voxel_size)
    
    current_points = len(np.asarray(pcd.points))
    
    # √âtape 2: Techniques de downsampling multi-√©tapes
    if current_points > target_points:
        remaining_reduction = current_points / target_points
        
        # Random sampling pour r√©duction initiale rapide
        if remaining_reduction > 4:
            random_ratio = min(0.5, target_points / current_points * 2)
            random_indices = np.random.choice(current_points, int(current_points * random_ratio), replace=False)
            pcd = pcd.select_by_index(random_indices)
            current_points = len(np.asarray(pcd.points))
        
        # Uniform grid sampling pour couverture spatiale
        if current_points > target_points and strategy in ['balanced', 'quality']:
            # Calcul de la taille de grille optimale
            points = np.asarray(pcd.points)
            bbox = points.max(axis=0) - points.min(axis=0)
            grid_density = (target_points / np.prod(bbox)) ** (1/3)
            grid_size = 1.0 / grid_density
            
            # Cr√©ation de la grille uniforme
            min_bounds = points.min(axis=0)
            grid_indices = ((points - min_bounds) / grid_size).astype(int)
            
            # S√©lection d'un point par cellule de grille
            unique_grids = {}
            for i, grid_idx in enumerate(grid_indices):
                grid_key = tuple(grid_idx)
                if grid_key not in unique_grids:
                    unique_grids[grid_key] = i
            
            selected_indices = list(unique_grids.values())
            
            if len(selected_indices) > target_points:
                # Si encore trop, sous-√©chantillonnage al√©atoire
                selected_indices = np.random.choice(selected_indices, target_points, replace=False)
            
            pcd = pcd.select_by_index(selected_indices)
            current_points = len(np.asarray(pcd.points))
        
        # Farthest point sampling pour qualit√© optimale
        if current_points > target_points and strategy == 'quality':
            # Impl√©mentation simplifi√©e du farthest point sampling
            points = np.asarray(pcd.points)
            n_points = len(points)
            
            # S√©lection du premier point al√©atoirement
            selected_indices = [np.random.randint(0, n_points)]
            distances = np.full(n_points, np.inf)
            
            for _ in range(min(target_points - 1, n_points - 1)):
                # Mise √† jour des distances
                last_selected = points[selected_indices[-1]]
                current_distances = np.linalg.norm(points - last_selected, axis=1)
                distances = np.minimum(distances, current_distances)
                
                # S√©lection du point le plus √©loign√©
                farthest_idx = np.argmax(distances)
                selected_indices.append(farthest_idx)
                
                # Marquer comme s√©lectionn√©
                distances[farthest_idx] = 0
            
            pcd = pcd.select_by_index(selected_indices)
    
    # √âtape 3: Pr√©servation des attributs
    if preserve_colors and pcd.has_colors():
        # Les couleurs sont automatiquement pr√©serv√©es par select_by_index
        pass
    
    if preserve_normals and pcd.has_normals():
        # Recalcul des normales si n√©cessaire apr√®s downsampling
        pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))
        pcd.orient_normals_consistent_tangent_plane(k=15)
    
    # M√©triques finales
    final_points = len(np.asarray(pcd.points))
    processing_time = time.time() - start_time
    
    return pcd

def apply_pointnet_classification(pcd, confidence_threshold=0.7):
    """
    Classification simplifi√©e inspir√©e de PointNet pour nuages de points photogramm√©triques.
    
    Utilise des caract√©ristiques g√©om√©triques simples pour classifier :
    - Terrain (bas, plat)
    - B√¢timents (vertical, r√©gulier)
    - V√©g√©tation (haut, irr√©gulier)
    - V√©hicules (petit, mobile)
    
    Args:
        pcd: Point cloud Open3D
        confidence_threshold: Seuil de confiance minimum
        
    Returns:
        Tuple (pcd_classified, classification_stats)
    """
    import time
    start_time = time.time()
    
    # R√©cup√©ration des points et couleurs
    points = np.asarray(pcd.points)
    colors = np.asarray(pcd.colors) if pcd.has_colors() else np.ones((len(points), 3)) * 0.5
    
    n_points = len(points)
    
    # Calcul des caract√©ristiques g√©om√©triques (inspir√© de PointNet)
    
    # 1. Coordonn√©es normalis√©es (centrage - invariance translationnelle)
    centroid = np.mean(points, axis=0)
    points_centered = points - centroid
    
    # 2. Calcul des normales si pas pr√©sentes (pour caract√©ristiques g√©om√©triques)
    if not pcd.has_normals():
        pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))
    
    normals = np.asarray(pcd.normals)
    
    # 3. Calcul des caract√©ristiques locales (k-NN comme dans PointNet++)
    from sklearn.neighbors import NearestNeighbors
    nbrs = NearestNeighbors(n_neighbors=min(32, n_points), algorithm='auto').fit(points_centered)
    distances, indices = nbrs.kneighbors(points_centered)
    
    # Caract√©ristiques g√©om√©triques pour chaque point
    features = []
    
    for i in range(n_points):
        local_points = points_centered[indices[i]]
        local_normals = normals[indices[i]]
        
        # Caract√©ristiques inspir√©es de PointNet :
        # - √âcart-type des positions locales (rugosit√©)
        # - Verticalit√© (angle avec Z)
        # - Densit√© locale
        # - Couleur moyenne
        
        # Rugosit√© locale (√©cart-type des distances)
        roughness = np.std(distances[i])
        
        # Verticalit√© (angle de la normale avec l'axe Z)
        verticality = abs(normals[i][2])  # Composante Z de la normale
        
        # Densit√© locale (inverse de la distance moyenne)
        local_density = 1.0 / (np.mean(distances[i]) + 1e-6)
        
        # Couleur (luminosit√© moyenne)
        brightness = np.mean(colors[i]) if len(colors[i]) > 0 else 0.5
        
        # Altitude relative (par rapport au centro√Øde)
        relative_height = points[i][2] - centroid[2]
        
        features.append([roughness, verticality, local_density, brightness, relative_height])
    
    features = np.array(features)
    
    # Classification bas√©e sur des r√®gles simples (version simplifi√©e de PointNet)
    classifications = []
    confidences = []
    
    for feat in features:
        roughness, verticality, density, brightness, height = feat
        
        # R√®gles de classification inspir√©es de l'analyse g√©om√©trique
        
        # Terrain : bas, plat, haute densit√©
        if height < np.percentile(features[:, 4], 25) and verticality > 0.8 and roughness < np.percentile(features[:, 0], 50):
            class_id = 0  # Terrain
            confidence = min(0.9, verticality * 0.8 + (1 - roughness) * 0.2)
            
        # B√¢timents : vertical, r√©gulier, hauteur moyenne
        elif verticality > 0.6 and roughness < np.percentile(features[:, 0], 75) and abs(height) < np.percentile(np.abs(features[:, 4]), 75):
            class_id = 1  # B√¢timents
            confidence = min(0.85, verticality * 0.7 + (1 - roughness) * 0.3)
            
        # V√©g√©tation : irr√©gulier, vertical variable, haute
        elif roughness > np.percentile(features[:, 0], 50) and height > np.percentile(features[:, 4], 50):
            class_id = 2  # V√©g√©tation
            confidence = min(0.8, roughness * 0.6 + (height / (np.max(features[:, 4]) + 1e-6)) * 0.4)
            
        # V√©hicules/Objets : petit, isol√©, basse densit√©
        elif density < np.percentile(features[:, 2], 25) and abs(height) < np.percentile(np.abs(features[:, 4]), 50):
            class_id = 3  # V√©hicules/Objets
            confidence = min(0.75, (1 - density/np.max(features[:, 2])) * 0.6 + 0.4)
            
        else:
            class_id = 4  # Autres
            confidence = 0.5
            
        classifications.append(class_id)
        confidences.append(confidence)
    
    # Application des couleurs selon la classification (seulement si confiance suffisante)
    classified_colors = colors.copy()
    
    # Palette de couleurs pour chaque classe
    class_colors = {
        0: [0.4, 0.8, 0.4],  # Terrain - Vert
        1: [0.8, 0.4, 0.4],  # B√¢timents - Rouge
        2: [0.4, 0.4, 0.8],  # V√©g√©tation - Bleu
        3: [0.8, 0.8, 0.4],  # V√©hicules - Jaune
        4: [0.6, 0.6, 0.6],  # Autres - Gris
    }
    
    classified_count = 0
    for i, (class_id, conf) in enumerate(zip(classifications, confidences)):
        if conf >= confidence_threshold:
            classified_colors[i] = class_colors[class_id]
            classified_count += 1
    
    # Mise √† jour des couleurs du point cloud
    pcd.colors = o3d.utility.Vector3dVector(classified_colors)
    
    # Statistiques
    processing_time = (time.time() - start_time) * 1000
    
    # Comptage par classe
    class_counts = {}
    for class_id in range(5):
        count = sum(1 for c, conf in zip(classifications, confidences) 
                   if c == class_id and conf >= confidence_threshold)
        class_counts[class_id] = count
    
    stats = {
        'classified_objects': classified_count,
        'avg_confidence': np.mean([c for c in confidences if c >= confidence_threshold]) if classified_count > 0 else 0,
        'processing_time_ms': processing_time,
        'gpu_memory_mb': 0,  # Pas utilis√© pour cette version simplifi√©e
        'class_distribution': class_counts,
        'total_points': n_points
    }
    
    return pcd, stats

# Fonction pour m√©triques GPU/CPU
@st.cache_data(ttl=10)
def get_system_metrics(device):
    if PSUTIL_AVAILABLE:
        cpu_percent = psutil.cpu_percent(interval=1)
        ram_percent = psutil.virtual_memory().percent
        metrics = {"CPU %": f"{cpu_percent:.1f}%", "RAM %": f"{ram_percent:.1f}%"}
    else:
        metrics = {"CPU %": "N/A", "RAM %": "N/A"}
    if device == 'cuda' and NVML_AVAILABLE:
        gpu_util = pynvml.nvmlDeviceGetUtilizationRates(pynvml.nvmlDeviceGetHandleByIndex(0)).gpu
        gpu_mem = pynvml.nvmlDeviceGetMemoryInfo(pynvml.nvmlDeviceGetHandleByIndex(0)).used / 1024**3
        gpu_temp = pynvml.nvmlDeviceGetTemperature(pynvml.nvmlDeviceGetHandleByIndex(0), pynvml.NVML_TEMPERATURE_GPU)
        if gpu_temp > 85:
            st.sidebar.warning(f"üö® GPU surchauffe ! Temp: {gpu_temp}¬∞C ‚Äì D√©sactivez GPU via checkbox.")
        metrics.update({"GPU %": f"{gpu_util:.1f}%", "GPU Temp": f"{gpu_temp}¬∞C", "GPU Mem": f"{gpu_mem:.1f}GB"})
    return metrics

def setup_sidebar_monitoring(device):
    """Configure le monitoring syst√®me dans la sidebar"""
    with st.sidebar:
        st.header("üìà Monitoring Syst√®me")
        metrics = get_system_metrics(device)
        for key, value in metrics.items():
            st.metric(key, value)

        st.header("üßπ Lib√©ration M√©moire")
        if st.button("Lib√©rer M√©moire GPU"):
            if torch.cuda.is_available():
                torch.cuda.synchronize()
                mem_before = torch.cuda.memory_allocated() / 1024**3
                models.clear()
                gc.collect()
                torch.cuda.synchronize()
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                mem_after = torch.cuda.memory_allocated() / 1024**3
                st.success(f"M√©moire GPU lib√©r√©e ! Avant: {mem_before:.2f} GB, Apr√®s: {mem_after:.2f} GB (Diff: {mem_before - mem_after:.2f} GB)")
            else:
                st.info("Aucun GPU d√©tect√©.")

        if st.button("Lib√©rer M√©moire CPU"):
            gc.collect()
            st.success("M√©moire CPU lib√©r√©e !")

        if st.button("Lib√©rer RAM"):
            gc.collect()
            st.success("RAM lib√©r√©e !")

# Appeler les fonctions de configuration au d√©but
device = setup_ui()
setup_sidebar_monitoring(device)

# Chargement des mod√®les
def load_dust3r_model():
    if 'dust3r' not in models:
        try:
            model_name = "naver/DUSt3R_ViTLarge_BaseDecoder_512_dpt"
            model = AsymmetricCroCo3DStereo.from_pretrained(model_name).to(device)
            models['dust3r'] = model
            st.success("Mod√®le DUSt3R charg√© avec succ√®s !")
        except Exception as e:
            st.error(f"Erreur lors du chargement du mod√®le DUSt3R : {e}")
            st.info("Assurez-vous d'avoir install√© DUSt3R : `pip install git+https://github.com/naver/dust3r.git`")
            return None
    return models.get('dust3r')

    return models.get('dust3r')

def load_clip_model():
    if 'clip' not in models:
        try:
            # Chercher CLIP local d'abord
            clip_path = Path(__file__).parent / "models--openai--clip-vit-base-patch32"
            if clip_path.exists():
                snapshots_dir = clip_path / "snapshots"
                if snapshots_dir.exists():
                    snapshot_dirs = list(snapshots_dir.iterdir())
                    if snapshot_dirs:
                        model = CLIPModel.from_pretrained(str(snapshot_dirs[0])).to(device)  # type: ignore
                        processor = CLIPProcessor.from_pretrained(str(snapshot_dirs[0]))
                    else:
                        model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(device)  # type: ignore
                        processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
                else:
                    model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(device)  # type: ignore
                    processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
            else:
                model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(device)  # type: ignore
                processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
            
            models['clip'] = (model, processor)
        except Exception as e:
            st.error(f"Erreur lors du chargement de CLIP : {e}")
            return None, None
    return models.get('clip', (None, None))

# Fonction de d√©tection de changements 4D inspir√©e de Py4DGeo
@st.cache_data(ttl=300)
def apply_4d_change_detection(pcd1, pcd2, cylinder_radius=0.1, min_points=10, 
                             confidence_threshold=0.95, max_distance=1.0):
    """
    Impl√©mente l'algorithme M3C2 (Multiscale Model-to-Model Cloud Comparison) 
    pour d√©tecter les changements entre deux nuages de points temporels.
    
    Args:
        pcd1: Premier nuage de points (Open3D PointCloud) - √©poque de r√©f√©rence
        pcd2: Second nuage de points (Open3D PointCloud) - √©poque de comparaison  
        cylinder_radius: Rayon des cylindres locaux pour l'analyse (m√®tres)
        min_points: Nombre minimum de points requis dans un cylindre
        confidence_threshold: Seuil de confiance pour la classification des changements
        max_distance: Distance maximale pour consid√©rer un changement significatif
        
    Returns:
        pcd_diff: Nuage de points avec couleurs codant les changements
        stats: Statistiques des changements d√©tect√©s
    """
    try:
        import time
        start_time = time.time()
        
        # V√©rifier les entr√©es
        if pcd1 is None or pcd2 is None:
            raise ValueError("Les deux nuages de points doivent √™tre fournis")
            
        points1 = np.asarray(pcd1.points)
        points2 = np.asarray(pcd2.points)
        
        if len(points1) == 0 or len(points2) == 0:
            raise ValueError("Les nuages de points ne peuvent pas √™tre vides")
        
        st.info(f"üîç Analyse 4D en cours... Points r√©f√©rence: {len(points1)}, Points comparaison: {len(points2)}")
        
        # Construire l'arbre KD pour le nuage de r√©f√©rence
        from scipy.spatial import cKDTree
        tree1 = cKDTree(points1)
        tree2 = cKDTree(points2)
        
        # Calculer les distances sign√©es pour chaque point du nuage 1
        distances_signed = []
        confidences = []
        valid_points = []
        
        progress_bar = st.progress(0)
        total_points = len(points1)
        
        for i, point in enumerate(points1):
            if i % 1000 == 0:
                progress_bar.progress(i / total_points)
            
            # Trouver les voisins dans le cylindre pour le point de r√©f√©rence
            indices1 = tree1.query_ball_point(point, cylinder_radius)
            
            if len(indices1) < min_points:
                continue  # Pas assez de points locaux
                
            # Calculer le centro√Øde local et la normale approximative
            local_points1 = points1[indices1]
            centroid1 = np.mean(local_points1, axis=0)
            
            # Calculer la normale approximative via SVD
            centered_points = local_points1 - centroid1
            _, _, vh = np.linalg.svd(centered_points.T @ centered_points)
            normal = vh[-1]  # Derni√®re colonne = direction de plus faible variance
            
            # D√©finir le cylindre le long de la normale
            cylinder_height = cylinder_radius * 2
            
            # Calculer la distance sign√©e moyenne dans le cylindre
            distances_local = []
            
            for p in local_points1:
                # Projeter sur la normale
                vec = p - centroid1
                proj_distance = np.dot(vec, normal)
                
                if abs(proj_distance) <= cylinder_height / 2:
                    # Trouver le point le plus proche dans le nuage 2
                    dist, idx = tree2.query(p)
                    if dist <= max_distance:
                        point2 = points2[idx]
                        signed_dist = np.dot(point2 - p, normal)
                        distances_local.append(signed_dist)
            
            if len(distances_local) >= min_points:
                # Distance moyenne sign√©e
                mean_distance = np.mean(distances_local)
                distances_signed.append(mean_distance)
                valid_points.append(point)
                
                # Calculer la confiance bas√©e sur la variance locale
                if len(distances_local) > 1:
                    std_distance = np.std(distances_local)
                    confidence = 1.0 / (1.0 + std_distance)  # Confiance inversement proportionnelle √† la variance
                else:
                    confidence = 0.5
                confidences.append(confidence)
        
        progress_bar.progress(1.0)
        progress_bar.empty()
        
        if len(distances_signed) == 0:
            st.warning("Aucun changement d√©tectable trouv√© avec les param√®tres actuels")
            return pcd1, {'error': 'no_changes_detected'}
        
        # Convertir en arrays numpy
        distances_signed = np.array(distances_signed)
        confidences = np.array(confidences)
        valid_points = np.array(valid_points)
        
        # Classification des changements avec seuillage statistique
        # Utiliser une approche robuste avec m√©diane et MAD (Median Absolute Deviation)
        median_dist = np.median(distances_signed)
        mad_dist = np.median(np.abs(distances_signed - median_dist))
        
        # Seuil adaptatif bas√© sur la distribution
        threshold = 3 * mad_dist if mad_dist > 0 else 0.01
        
        # Classification
        erosion_mask = (distances_signed < -threshold) & (confidences > confidence_threshold)
        deposition_mask = (distances_signed > threshold) & (confidences > confidence_threshold)
        stable_mask = ~erosion_mask & ~deposition_mask
        
        # Cr√©er le nuage de points color√©
        pcd_diff = o3d.geometry.PointCloud()
        pcd_diff.points = o3d.utility.Vector3dVector(valid_points)
        
        # Palette de couleurs pour les changements
        colors = np.zeros((len(valid_points), 3))
        
        # Erosion: rouge
        colors[erosion_mask] = [1.0, 0.0, 0.0]  # Rouge
        
        # D√©p√¥t: bleu
        colors[deposition_mask] = [0.0, 0.0, 1.0]  # Bleu
        
        # Stable: vert/gris
        colors[stable_mask] = [0.5, 0.5, 0.5]  # Gris
        
        # Intensit√© bas√©e sur la magnitude du changement
        erosion_magnitude = np.abs(distances_signed[erosion_mask])
        deposition_magnitude = np.abs(distances_signed[deposition_mask])
        
        if len(erosion_magnitude) > 0:
            max_erosion = np.max(erosion_magnitude)
            if max_erosion > 0:
                erosion_intensity = erosion_magnitude / max_erosion
                colors[erosion_mask] = np.column_stack([
                    np.ones(len(erosion_intensity)),  # R
                    1 - erosion_intensity * 0.5,      # G (diminue avec l'intensit√©)
                    1 - erosion_intensity * 0.5       # B (diminue avec l'intensit√©)
                ])
        
        if len(deposition_magnitude) > 0:
            max_deposition = np.max(deposition_magnitude)
            if max_deposition > 0:
                deposition_intensity = deposition_magnitude / max_deposition
                colors[deposition_mask] = np.column_stack([
                    1 - deposition_intensity * 0.5,  # R (diminue avec l'intensit√©)
                    1 - deposition_intensity * 0.5,  # G (diminue avec l'intensit√©)
                    np.ones(len(deposition_intensity)) # B
                ])
        
        pcd_diff.colors = o3d.utility.Vector3dVector(colors)
        
        # Statistiques d√©taill√©es
        processing_time = (time.time() - start_time) * 1000
        
        stats = {
            'total_points_analyzed': len(valid_points),
            'erosion_points': np.sum(erosion_mask),
            'deposition_points': np.sum(deposition_mask),
            'stable_points': np.sum(stable_mask),
            'mean_change_magnitude': float(np.mean(np.abs(distances_signed))),
            'max_change_magnitude': float(np.max(np.abs(distances_signed))),
            'median_change': float(median_dist),
            'mad_threshold': float(mad_dist),
            'processing_time_ms': processing_time,
            'confidence_stats': {
                'mean': float(np.mean(confidences)),
                'median': float(np.median(confidences)),
                'high_confidence_ratio': float(np.mean(confidences > confidence_threshold))
            },
            'change_distribution': {
                'erosion_volume': float(np.sum(distances_signed[erosion_mask])),
                'deposition_volume': float(np.sum(distances_signed[deposition_mask])),
                'net_change': float(np.sum(distances_signed))
            }
        }
        
        st.success(f"‚úÖ Analyse 4D termin√©e ! {stats['erosion_points']} √©rosions, {stats['deposition_points']} d√©p√¥ts d√©tect√©s")
        
        return pcd_diff, stats
        
    except Exception as e:
        st.error(f"Erreur lors de l'analyse 4D : {str(e)}")
        return None, {'error': str(e)}

# Interface principale
col1, col2 = st.columns([1, 3])

with col1:
    st.header("üìÅ Upload d'Images")
    uploaded_files = st.file_uploader(
        "Choisissez des images (JPEG, PNG, etc.)",
        type=['jpg', 'jpeg', 'png', 'bmp'],
        accept_multiple_files=True,
        help="Chargez au moins 2 images pour une reconstruction 3D."
    )
   
    if uploaded_files:
        st.write(f"Nombre d'images charg√©es : {len(uploaded_files)}")
    
    # G√©or√©f√©rencement pour topographie
    enable_georef = st.checkbox("üìç Activer g√©or√©f√©rencement (coordonn√©es GPS)", value=False, key="enable_georef", 
                               help="Ajoutez des coordonn√©es GPS pour chaque image pour g√©or√©f√©rencer le nuage de points en coordonn√©es absolues (n√©cessaire pour la topographie).")
    
    gps_data = {}
    if enable_georef and uploaded_files:
        st.subheader("üåç Coordonn√©es GPS par Image")
        st.markdown("Entrez les coordonn√©es GPS (latitude, longitude, altitude) pour chaque image. Utilisez l'EXIF des photos ou un GPS externe pour pr√©cision topographique.")
        
        for i, file in enumerate(uploaded_files):
            with st.expander(f"üì∑ Image {i+1}: {file.name}", expanded=False):
                col_gps1, col_gps2, col_gps3 = st.columns(3)
                with col_gps1:
                    lat = st.number_input(f"Latitude (¬∞)", value=st.session_state.get(f'lat_{i}', 0.0), format="%.8f", key=f"lat_{i}", 
                                         help="Latitude en degr√©s d√©cimaux (ex: 48.8566 pour Paris)")
                with col_gps2:
                    lon = st.number_input(f"Longitude (¬∞)", value=st.session_state.get(f'lon_{i}', 0.0), format="%.8f", key=f"lon_{i}",
                                         help="Longitude en degr√©s d√©cimaux (ex: 2.3522 pour Paris)")
                with col_gps3:
                    alt = st.number_input(f"Altitude (m)", value=st.session_state.get(f'alt_{i}', 0.0), format="%.2f", key=f"alt_{i}",
                                         help="Altitude en m√®tres au-dessus du niveau de la mer")
                gps_data[file.name] = {"lat": lat, "lon": lon, "alt": alt}
        
        st.session_state['gps_data'] = gps_data
        st.info("üí° Les coordonn√©es GPS seront utilis√©es pour transformer le nuage de points en coordonn√©es absolues apr√®s reconstruction.")
        
        # Bouton pour extraire GPS depuis EXIF
        if st.button("üìç Extraire GPS depuis EXIF des images", help="Remplit automatiquement les champs GPS depuis les m√©tadonn√©es EXIF des photos (n√©cessite GPS activ√© lors de la prise de vue)"):
            extracted_count = 0
            for i, file in enumerate(uploaded_files):
                with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.name)[1]) as tmp_file:
                    tmp_file.write(file.getbuffer())
                    tmp_path = tmp_file.name
                
                gps = get_gps_from_exif(tmp_path)
                os.unlink(tmp_path)
                
                if gps:
                    # Mettre √† jour session_state pour pr√©-remplir
                    st.session_state[f'lat_{i}'] = gps[0]
                    st.session_state[f'lon_{i}'] = gps[1]
                    st.session_state[f'alt_{i}'] = gps[2]
                    extracted_count += 1
                    st.success(f"‚úÖ GPS extrait pour {file.name}: Lat {gps[0]:.6f}¬∞, Lon {gps[1]:.6f}¬∞, Alt {gps[2]:.2f}m")
                else:
                    st.warning(f"‚ùå Pas de donn√©es GPS dans EXIF pour {file.name}")
            
            if extracted_count > 0:
                st.info("üîÑ Les champs ont √©t√© pr√©-remplis. Actualisez la page si n√©cessaire.")
            else:
                st.error("Aucune donn√©e GPS trouv√©e dans les EXIF des images.")
    
    # Options de traitement
    st.header("‚öôÔ∏è Options")
    model_choice = st.radio("Mod√®le de reconstruction", ["DUSt3R"], help="Choisissez DUSt3R pour une approche st√©r√©o ou MapAnything pour une reconstruction universelle metric 3D.")
    
    if model_choice == "DUSt3R":
        batch_size = st.slider("Taille du batch", min_value=1, max_value=8, value=1, key="batch_size", help="Nombre d'images trait√©es simultan√©ment (plus petit = plus stable sur GPU ; max augment√© pour scalabilit√©)")
        niter_align = st.slider("It√©rations d'alignement global", min_value=100, max_value=500, value=300, help="Nombre d'it√©rations pour l'optimisation globale")
        lr_align = st.slider("Taux d'apprentissage alignement", min_value=0.001, max_value=0.1, value=0.01, format="%.3f")
    
    threshold_conf = st.slider("Seuil de confiance", min_value=0.0, max_value=1.0, value=0.5, format="%.2f", key="threshold_conf", help="Seuil pour filtrer les points de confiance")
    max_points_per_view = st.slider("Max points par vue (downsample)", min_value=1000, max_value=100000, value=20000, help="Nombre max de points par image pour visualisation HD")
    scale_factor = st.slider("Facteur d'√©chelle pour profondeurs r√©alistes", min_value=0.5, max_value=3.0, value=1.0, step=0.1, help="Ajustez pour matcher les dimensions r√©elles de la sc√®ne (ex: 1.0 pour ~1m de profondeur typique)")
    generate_mesh = st.checkbox("G√©n√©rer maillage 3D haute qualit√©", value=False, key="generate_mesh_main", help="Cr√©e un maillage professionnel √† partir du nuage de points avec qualit√© Blender-like.")
    mesh_method = st.radio("M√©thode de reconstruction maillage", ["Poisson", "Ball Pivoting"], help="Poisson pour surfaces lisses ; Ball Pivoting pour maillages avec trous.")

    if generate_mesh:
        with st.expander("üé® Param√®tres Avanc√©s de Qualit√© du Maillage", expanded=False):
            st.markdown("**‚öôÔ∏è Ajustez ces param√®tres pour √©viter les 'maillages patates' et obtenir une qualit√© professionnelle**")

            mesh_quality_preset = st.selectbox("Pr√©r√©glage qualit√©", [
                "Standard (recommand√©)",
                "Haute qualit√© (plus lent)",
                "Ultra HD (tr√®s lent)",
                "Personnalis√©"
            ], key="mesh_quality_preset", help="Pr√©r√©glages optimis√©s pour diff√©rents niveaux de qualit√©")

            if mesh_quality_preset == "Standard (recommand√©)":
                mesh_voxel_size = 0.001
                mesh_normal_radius = 0.015
                mesh_normal_neighbors = 50
                mesh_orientation_iterations = 500
                mesh_smoothing_iterations = 5
                mesh_post_smoothing = 3
            elif mesh_quality_preset == "Haute qualit√© (plus lent)":
                mesh_voxel_size = 0.0005
                mesh_normal_radius = 0.01
                mesh_normal_neighbors = 80
                mesh_orientation_iterations = 800
                mesh_smoothing_iterations = 8
                mesh_post_smoothing = 5
            elif mesh_quality_preset == "Ultra HD (tr√®s lent)":
                mesh_voxel_size = 0.0002
                mesh_normal_radius = 0.005
                mesh_normal_neighbors = 100
                mesh_orientation_iterations = 1000
                mesh_smoothing_iterations = 10
                mesh_post_smoothing = 8
            else:  # Personnalis√©
                mesh_voxel_size = st.slider("Taille voxel (d√©tail)", 0.0001, 0.005, 0.001, 0.0001, key="mesh_voxel_size",
                                          help="Plus petit = plus de d√©tails mais plus lent (0.001 = 1mm)")
                mesh_normal_radius = st.slider("Rayon normales", 0.005, 0.05, 0.015, 0.005, key="mesh_normal_radius",
                                             help="Rayon pour estimation des normales de surface")
                mesh_normal_neighbors = st.slider("Voisins normales", 20, 150, 50, 10,
                                                help="Nombre de voisins pour calcul des normales")
                mesh_orientation_iterations = st.slider("It√©rations orientation", 200, 1500, 500, 100,
                                                      help="It√©rations pour orienter les normales de mani√®re coh√©rente")
                mesh_smoothing_iterations = st.slider("Lissage pr√©-maillage", 0, 20, 5, 1,
                                                    help="Lissage du nuage avant reconstruction")
                mesh_post_smoothing = st.slider("Lissage post-maillage", 0, 20, 3, 1,
                                              help="Lissage du maillage final")

            mesh_adaptive_depth = st.checkbox("Profondeur Poisson adaptative", value=True, key="mesh_adaptive_depth",
                                            help="Ajuste automatiquement la profondeur selon la densit√© du nuage")
            mesh_clean_artifacts = st.checkbox("Nettoyage artefacts avanc√©", value=True, key="mesh_clean_artifacts",
                                             help="Supprime triangles d√©g√©n√©r√©s et optimise la topologie")

    if mesh_method == "Poisson":
        if generate_mesh and not mesh_adaptive_depth:
            poisson_depth = st.slider("Profondeur maillage (Poisson)", min_value=5, max_value=14, value=10, key="poisson_depth",
                                    help="Niveau de d√©tail pour la reconstruction Poisson (plus √©lev√© = plus fin, mais plus gourmand).")
    else:
        ball_pivoting_max_radius = st.slider("Rayon max Ball Pivoting", min_value=0.001, max_value=0.1, value=0.02, step=0.001, format="%.3f",
                                           help="Rayon maximal pour pivoting (plus grand = plus de connexions, mais plus approximatif).")
    # Section informative sur les optimisations Voxel Grid Filtering
    with st.expander("üöÄ Optimisations Voxel Grid Filtering (Article Medium)", expanded=False):
        st.markdown("""
        **Bas√© sur l'article : "Understanding Voxel Grid Filtering: The Secret to Lightning-Fast Point Cloud Processing"**

        ### üéØ Optimisations Impl√©ment√©es :

        #### 1. **Voxel Size Adaptatif**
        - Analyse automatique de la densit√© locale du nuage
        - Ajustement intelligent selon le pr√©r√©glage qualit√© :
          - **Standard** : Agressif (r√©duction ~70-80%)
          - **High** : Mod√©r√© (r√©duction ~50-70%)
          - **Ultra HD** : Conservateur (r√©duction ~30-50%)

        #### 2. **Filtrage Statistique Avanc√©**
        - D√©tection d'outliers bas√©e sur distances inter-points
        - Seuil automatique : `moyenne + 2√ó√©cart-type`
        - Suppression des points aberrants pr√©servant la g√©om√©trie

        #### 3. **M√©triques de Performance**
        - Ratio de r√©duction en temps r√©el
        - Impact sur la qualit√© vs performance
        - Optimisation automatique selon la complexit√©

        ### üí° Avantages :
        - **Vitesse** : 10-100x plus rapide sur gros nuages
        - **M√©moire** : R√©duction drastique de l'usage RAM
        - **Qualit√©** : Pr√©servation des d√©tails importants
        - **Stabilit√©** : √âlimination des artefacts de reconstruction

        ### üéõÔ∏è Recommandations :
        - **Nuages denses (>1M points)** : Utilisez voxel size adaptatif
        - **G√©om√©tries complexes** : Privil√©giez Ultra HD avec filtrage l√©ger
        - **Performance critique** : Standard avec nettoyage artefacts activ√©
        """)

        # M√©triques en temps r√©el si disponibles
        if 'current_pcd_stats' in st.session_state:
            stats = st.session_state.current_pcd_stats
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Points Originaux", f"{stats.get('original_points', 'N/A'):,}")
            with col2:
                st.metric("Apr√®s Voxel", f"{stats.get('voxel_points', 'N/A'):,}")
            with col3:
                st.metric("Apr√®s Nettoyage", f"{stats.get('final_points', 'N/A'):,}")
            with col4:
                outliers = stats.get('outliers_removed', 0)
                st.metric("Outliers Supprim√©s", f"{outliers:,}" if outliers > 0 else "N/A")

    # Section informative sur le D√©bruitage Industriel Avanc√©
    denoising_key = f"denoising_expander_{hash('denoising')}"
    with st.expander("üî¨ D√©bruitage Industriel Avanc√© (Inspired by Vitreous/Telekinesis)", expanded=False):
        st.markdown("""
        **Inspir√© par l'article : "How to Denoise Industrial 3D Point Clouds in Python: 3D Filtering with Vitreous from Telekinesis"**

        ### üè≠ Pipeline de D√©bruitage Industriel Complet :

        #### 1. **Analyse Pr√©liminaire du Bruit**
        - Calcul automatique de la densit√© du nuage de points
        - Classification : tr√®s dense (>1000 pts/unit√©¬≥), dense (>100), sparse (<100)
        - Adaptation des param√®tres selon la complexit√© du nuage

        #### 2. **Filtrage Statistique Adaptatif**
        - **Statistical Outlier Removal** avec param√®tres dynamiques :
          - Nuages denses : 20 voisins, seuil 1.5œÉ
          - Nuages moyens : 30 voisins, seuil 2.0œÉ
          - Nuages sparses : 50 voisins, seuil 2.5œÉ

        #### 3. **Filtrage par Rayon (Radius Outlier Removal)**
        - Suppression des points isol√©s dans un rayon donn√©
        - Rayon adaptatif : `3 √ó voxel_size`
        - Seuil minimum : 16 voisins requis

        #### 4. **D√©bruitage Conditionnel par Densit√© Locale**
        - Analyse de densit√© locale pour chaque r√©gion
        - Filtrage plus strict dans les zones de faible densit√©
        - Pr√©servation des d√©tails dans les zones denses

        #### 5. **Lissage Moving Least Squares (MLS)**
        - Lissage polynomial adaptatif selon la qualit√© :
          - **Ultra HD** : Polyn√¥me degr√© 2, rayon petit (pr√©cision maximale)
          - **High** : Polyn√¥me degr√© 1, rayon moyen
          - **Standard** : Polyn√¥me degr√© 1, rayon large (performance)

        #### 6. **D√©bruitage des Couleurs**
        - Filtrage bilat√©ral des textures
        - M√©diane locale sur 15 voisins les plus proches
        - R√©duction du bruit colorim√©trique tout en pr√©servant les d√©tails

        ### üéØ Applications Industrielles :
        - **Scan laser industriels** : Suppression du bruit de capteur
        - **Photogramm√©trie** : Nettoyage des reconstructions DUST3R
        - **Inspection qualit√©** : Am√©lioration de la pr√©cision des mesures
        - **Reverse engineering** : Pr√©paration de donn√©es CAD propres

        ### üìä M√©triques de Performance :
        - **Taux de r√©duction du bruit** : Pourcentage de points supprim√©s
        - **Pr√©servation de la g√©om√©trie** : Maintien des d√©tails importants
        - **Temps de traitement** : Optimis√© pour les gros volumes
        """)

        # M√©triques du d√©bruitage en temps r√©el
        if 'denoising_stats' in st.session_state:
            stats = st.session_state.denoising_stats
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Points Avant D√©bruitage", f"{stats.get('original_points', 'N/A'):,}")
            with col2:
                st.metric("Points Apr√®s D√©bruitage", f"{stats.get('final_points', 'N/A'):,}")
            with col3:
                reduction = stats.get('noise_reduction_percent', 0)
                st.metric("Bruit Supprim√©", f"{reduction:.1f}%" if reduction > 0 else "N/A")
            with col4:
                filters_applied = sum([
                    stats.get('statistical_filter_applied', False),
                    stats.get('radius_filter_applied', False),
                    stats.get('mls_smoothing_applied', False),
                    stats.get('color_denoising_applied', False)
                ])
                st.metric("Filtres Appliqu√©s", f"{filters_applied}/4")

        # Contr√¥les avanc√©s pour le d√©bruitage
        st.markdown("### ‚öôÔ∏è Contr√¥les Avanc√©s du D√©bruitage")
        
        # Initialiser les valeurs par d√©faut dans le session state si elles n'existent pas
        if 'advanced_denoising_enabled' not in st.session_state:
            st.session_state.advanced_denoising_enabled = True
        if 'denoising_params' not in st.session_state:
            st.session_state.denoising_params = {
                'statistical_neighbors': 30,
                'radius_min_points': 16,
                'mls_polynomial_order': 1,
                'color_neighbors': 15
            }
        
        advanced_denoising = st.checkbox("Activer D√©bruitage Industriel Avanc√©", 
                                       value=st.session_state.advanced_denoising_enabled,
                                       key="advanced_denoising_checkbox",
                                       help="Pipeline complet de 6 √©tapes pour le d√©bruitage professionnel")
        st.session_state.advanced_denoising_enabled = advanced_denoising

        if advanced_denoising:
            col1, col2 = st.columns(2)
            with col1:
                statistical_neighbors = st.slider("Voisins pour filtrage statistique", 10, 100, 
                                                st.session_state.denoising_params['statistical_neighbors'],
                                                key="statistical_neighbors_slider",
                                                help="Nombre de voisins pour la d√©tection d'outliers statistiques")
                radius_min_points = st.slider("Points minimum par rayon", 5, 50,
                                            st.session_state.denoising_params['radius_min_points'],
                                            key="radius_min_points_slider",
                                            help="Nombre minimum de voisins dans le rayon pour validation")
            with col2:
                mls_polynomial_order = st.selectbox("Ordre polynomial MLS", [1, 2],
                                                  index=st.session_state.denoising_params['mls_polynomial_order'] - 1,
                                                  key="mls_polynomial_order_select",
                                                  help="Degr√© du polyn√¥me pour le lissage (2 = plus pr√©cis mais lent)")
                color_neighbors = st.slider("Voisins pour d√©bruitage couleurs", 5, 30,
                                          st.session_state.denoising_params['color_neighbors'],
                                          key="color_neighbors_slider",
                                          help="Nombre de voisins pour le filtrage bilat√©ral des couleurs")

            # Mise √† jour des param√®tres
            st.session_state.denoising_params = {
                'statistical_neighbors': statistical_neighbors,
                'radius_min_points': radius_min_points,
                'mls_polynomial_order': mls_polynomial_order,
                'color_neighbors': color_neighbors
            }
            st.session_state.advanced_denoising_params = st.session_state.denoising_params

    # Section informative sur le Downsampling Temps R√©el
    with st.expander("‚ö° Downsampling Temps R√©el Ultra-Rapide (Inspired by Sohail Saifi)", expanded=False):
        st.markdown("""
        **Inspir√© par l'article : "Building a Real-Time Point Cloud Downsampling Pipeline from 10M to 100K Points in Milliseconds"**

        ### üöÄ Pipeline de Downsampling Temps R√©el :

        #### 1. **Analyse Adaptative du Volume**
        - **Ultra-Fast** (>10M points) : Pipeline optimis√© pour la vitesse pure
        - **Fast** (>1M points) : √âquilibre vitesse/qualit√©
        - **Quality** (<1M points) : Focus sur la pr√©servation des d√©tails

        #### 2. **Pr√©-downsampling par Voxels**
        - R√©duction rapide des volumes massifs (>5M points)
        - Taille de voxel adaptative selon la densit√©
        - Pr√©paration pour les √©tapes suivantes

        #### 3. **Techniques de Downsampling Multi-√©tapes**

        ##### **Random Sampling (Ultra-rapide)**
        - S√©lection al√©atoire pour r√©duction initiale
        - Id√©al pour gros volumes o√π la vitesse prime

        ##### **Uniform Grid Sampling (√âquilibr√©)**
        - Division de l'espace en grille r√©guli√®re
        - Un point par cellule pour couverture uniforme
        - Pr√©serve la distribution spatiale

        ##### **Farthest Point Sampling (Qualit√© optimale)**
        - S√©lection it√©rative des points les plus √©loign√©s
        - Couverture spatiale maximale
        - Qualit√© sup√©rieure pour l'analyse

        #### 4. **Optimisation et M√©triques**
        - Calcul temps r√©el des performances
        - M√©triques de compression et couverture spatiale
        - Validation de l'atteinte des objectifs

        ### üéØ Applications Temps R√©el :
        - **LiDAR streaming** : Traitement de donn√©es en direct
        - **Robotique** : Navigation avec contraintes de performance
        - **AR/VR** : Rendu temps r√©el de sc√®nes complexes
        - **Inspection industrielle** : Analyse rapide de gros volumes

        ### ‚ö° Performances Cibles :
        - **10M ‚Üí 100K points** : Quelques millisecondes
        - **Traitement parall√®le** : Utilisation de tous les c≈ìurs CPU
        - **M√©moire optimis√©e** : Traitement par blocs si n√©cessaire
        - **Scalabilit√©** : Adapt√© aux GPUs pour volumes extr√™mes
        """)

        # Contr√¥les du downsampling temps r√©el
        st.markdown("### üéõÔ∏è Contr√¥les du Downsampling Temps R√©el")

        enable_realtime_downsampling = st.checkbox("Activer Downsampling Temps R√©el Ultra-Rapide", value=True, key="enable_realtime_downsampling",
                                                 help="Pipeline de r√©duction ultra-rapide pour gros nuages de points")

        if enable_realtime_downsampling:
            col1, col2, col3 = st.columns(3)
            with col1:
                target_points_options = [10000, 25000, 50000, 100000, 250000, 500000]
                target_points = st.selectbox("Points cibles", target_points_options, index=3,
                                           key="target_points",
                                           help="Nombre de points souhait√© apr√®s downsampling")
                st.session_state.downsampling_target = target_points

            with col2:
                downsampling_strategy = st.selectbox("Strat√©gie prioritaire",
                                                   ["auto", "speed", "quality", "balanced"],
                                                   index=0,
                                                   key="downsampling_strategy",
                                                   help="Strat√©gie de downsampling : auto=adaptatif, speed=vitesse max, quality=qualit√© max")

            with col3:
                preserve_colors = st.checkbox("Pr√©server les couleurs", value=True,
                                            key="preserve_colors",
                                            help="Maintenir les informations de couleur lors du downsampling")
                preserve_normals = st.checkbox("Pr√©server les normales", value=False,
                                             key="preserve_normals",
                                             help="Maintenir les normales de surface (plus lent)")

        # M√©triques du downsampling temps r√©el
        if 'realtime_downsampling_stats' in st.session_state:
            stats = st.session_state.realtime_downsampling_stats
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Points Originaux", f"{stats.get('original_points', 'N/A'):,}")
            with col2:
                st.metric("Points Finaux", f"{stats.get('final_points', 'N/A'):,}")
            with col3:
                processing_time = stats.get('processing_time_ms', 0)
                st.metric("Temps (ms)", f"{processing_time:.1f}" if processing_time > 0 else "N/A")
            with col4:
                compression = stats.get('compression_ratio', 0)
                st.metric("Compression", f"{compression:.1f}x" if compression > 0 else "N/A")

            # Indicateur de succ√®s
            target_achieved = stats.get('target_achieved', False)
            if target_achieved:
                st.success("üéØ Objectif de downsampling atteint !")
            else:
                st.warning("‚ö†Ô∏è Objectif partiellement atteint - augmenter la cible si n√©cessaire")

    # Section ML sur Nuages de Points (Inspired by hc's Medium article)
    with st.expander("üß† ML sur Nuages de Points - Classification & Segmentation (Inspired by hc's Medium Article)", expanded=False):
        st.markdown("""
        **Inspir√© par l'article : "Performing ML on Point-Clouds"**

        ### üéØ Techniques de ML sur Nuages de Points :

        #### 1. **PointNet (2017) - Classification Directe**
        - **Traitement direct** : Pas de voxelisation co√ªteuse en m√©moire
        - **Invariance de permutation** : Max-pooling respecte l'ordre des points
        - **Spatial Transformers** : Gestion invariance rotation/translation
        - **Fusion local-global** : Features individuels + features globales

        #### 2. **Point-Voxel CNN (PVCNN) (2019) - Meilleur des Deux Mondes**
        - **Architecture hybride** : Voxelisation grossi√®re + traitement direct
        - **Information d'adjacence** : Capture les relations de voisinage
        - **Optimisation m√©moire** : 7x moins de m√©moire que PointNet
        - **Performance** : 10x plus rapide

        #### 3. **Point Transformer (2020) - Attention-based**
        - **M√©canismes d'attention** : Capture interactions locales/globales
        - **Regroupement intelligent** : Voisins proches par rayon limit√©
        - **√âvolutivit√©** : Gestion des gros volumes de donn√©es
        - **√âtat de l'art** : Performance sup√©rieure

        ### üöÄ Applications dans la Photogramm√©trie :

        #### **Classification d'Objets**
        - B√¢timents, V√©hicules, V√©g√©tation, Terrain
        - Analyse urbaine automatique
        - Inspection industrielle

        #### **Segmentation S√©mantique**
        - S√©paration fa√ßade/toit/terrain
        - Identification mat√©riaux
        - Analyse de d√©fauts

        #### **D√©tection d'Anomalies**
        - Artefacts de reconstruction
        - Zones de faible qualit√©
        - Incoh√©rences g√©om√©triques

        #### **Optimisation Adaptative**
        - Param√®tres selon type de sc√®ne
        - Qualit√© pr√©dictive
        - Reconstruction guid√©e
        """)

        # Contr√¥les ML
        enable_ml_processing = st.checkbox("Activer Traitement ML sur Nuages de Points", value=False, key="enable_ml_processing",
                                         help="Classification et segmentation intelligentes des objets")

        if enable_ml_processing:
            col1, col2, col3 = st.columns(3)
            with col1:
                ml_technique = st.selectbox("Technique ML",
                                          ["PointNet (Classification)", "PVCNN (Hybride)", "PointTransformer (Attention)"],
                                          index=0,
                                          key="ml_technique",
                                          help="Algorithme de ML √† utiliser")

            with col2:
                ml_task = st.selectbox("T√¢che ML",
                                     ["Classification d'objets", "Segmentation s√©mantique", "D√©tection d'anomalies"],
                                     index=0,
                                     key="ml_task",
                                     help="Type de t√¢che √† effectuer")

            with col3:
                ml_confidence_threshold = st.slider("Seuil de confiance", 0.1, 1.0, 0.7,
                                                  help="Seuil minimum de confiance pour les pr√©dictions")

            # Sauvegarde des param√®tres ML dans session state
            # Note: Les param√®tres ML sont automatiquement g√©r√©s par Streamlit via les cl√©s des widgets
            # st.session_state.ml_technique = ml_technique
            # st.session_state.ml_task = ml_task
            # st.session_state.ml_confidence_threshold = ml_confidence_threshold

            # M√©triques ML
            if 'ml_processing_stats' in st.session_state:
                stats = st.session_state.ml_processing_stats
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Objets Classifi√©s", f"{stats.get('classified_objects', 0)}")
                with col2:
                    st.metric("Confiance Moyenne", f"{stats.get('avg_confidence', 0):.2f}")
                with col3:
                    st.metric("Temps ML (ms)", f"{stats.get('processing_time_ms', 0):.1f}")
                with col4:
                    st.metric("M√©moire GPU (MB)", f"{stats.get('gpu_memory_mb', 0):.0f}")

        # ============================================
        # ANALYSE 4D TEMPORELLE (CHANGEMENTS)
        # ============================================
        st.subheader("‚è∞ Analyse 4D Temporelle (D√©tection de Changements)")

        enable_4d_analysis = st.checkbox("üîç Activer Analyse 4D (Py4DGeo-inspired)", value=False, key="enable_4d_analysis",
                                       help="D√©tecte les changements temporels entre deux nuages de points (√©rosions, d√©p√¥ts, glissements)")

        if enable_4d_analysis:
            st.markdown("""
            **üß™ Analyse temporelle avanc√©e** inspir√©e de Py4DGeo pour d√©tecter:
            - **√ârosions**: Zones de perte de mati√®re (rouge)
            - **D√©p√¥ts**: Zones d'accumulation (bleu)
            - **Changements morphologiques**: Glissements, affaissements
            - **√âvolution urbaine**: Construction/destruction
            """)

            # Upload du nuage de r√©f√©rence (√©poque 1)
            col_ref, col_comp = st.columns(2)
            with col_ref:
                st.markdown("**üìÖ √âpoque de R√©f√©rence (T1)**")
                reference_pcd = st.file_uploader(
                    "Nuage de points r√©f√©rence (.ply, .pcd)",
                    type=['ply', 'pcd'],
                    key='reference_pcd',
                    help="Premier nuage de points (√©poque ancienne)"
                )

            with col_comp:
                st.markdown("**üìÖ √âpoque de Comparaison (T2)**")
                comparison_pcd = st.file_uploader(
                    "Nuage de points comparaison (.ply, .pcd)",
                    type=['ply', 'pcd'],
                    key='comparison_pcd',
                    help="Second nuage de points (√©poque r√©cente)"
                )

            # Param√®tres M3C2
            with st.expander("‚öôÔ∏è Param√®tres M3C2 (Multiscale Model-to-Model Cloud Comparison)", expanded=False):
                col1, col2, col3 = st.columns(3)
                with col1:
                    cylinder_radius = st.slider("Rayon des cylindres (m)", 0.01, 1.0, 0.1, 0.01,
                                              help="Rayon des cylindres locaux pour l'analyse (plus petit = plus pr√©cis)")

                with col2:
                    min_points_cylinder = st.slider("Points min/cylindre", 5, 50, 10,
                                                  help="Nombre minimum de points requis dans chaque cylindre")

                with col3:
                    confidence_threshold_4d = st.slider("Seuil de confiance", 0.5, 0.99, 0.95, 0.01,
                                                      help="Seuil de confiance pour la classification des changements")

                max_distance_4d = st.slider("Distance max de recherche (m)", 0.1, 5.0, 1.0, 0.1,
                                          help="Distance maximale pour trouver les correspondances entre nuages")

            # Sauvegarde des param√®tres 4D
            # Note: enable_4d_analysis est automatiquement g√©r√© par Streamlit via la cl√© du widget
            st.session_state.cylinder_radius = cylinder_radius
            st.session_state.min_points_cylinder = min_points_cylinder
            st.session_state.confidence_threshold_4d = confidence_threshold_4d
            st.session_state.max_distance_4d = max_distance_4d

            # M√©triques 4D si disponibles
            if '4d_analysis_stats' in st.session_state:
                stats_4d = st.session_state['4d_analysis_stats']
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Points Analys√©s", f"{stats_4d.get('total_points_analyzed', 0)}")
                with col2:
                    st.metric("√ârosions", f"{stats_4d.get('erosion_points', 0)}")
                with col3:
                    st.metric("D√©p√¥ts", f"{stats_4d.get('deposition_points', 0)}")
                with col4:
                    st.metric("Changement Moyen", f"{stats_4d.get('mean_change_magnitude', 0):.3f}m")

    # Am√©lioration : Option pour visualiser la coque convexe
    show_hull = st.checkbox("Afficher la coque convexe autour du maillage", value=True, key="show_hull_main", help="Ajoute une coque convexe pour mieux visualiser les limites de la sc√®ne dans Open3D.")
    
    # Nouvelle fonctionnalit√© : Analyse g√©om√©trique automatique RANSAC
    enable_auto_ransac = st.checkbox("üî¨ Activer analyse g√©om√©trique automatique (RANSAC)", value=False, key="enable_auto_ransac", 
                                    help="D√©tecte automatiquement plans, cylindres et sph√®res dans le nuage de points et les colore dans la visualisation Open3D.")
    
    # Valeurs par d√©faut pour √©viter les erreurs Pylance
    ransac_auto_threshold = 0.02
    ransac_auto_iterations = 1000
    
    if enable_auto_ransac:
        ransac_auto_threshold = st.slider("Seuil automatique RANSAC", 0.01, 0.1, 0.02, 0.005, 
                                         help="Seuil de distance pour la d√©tection automatique (plus petit = plus strict).")
        ransac_auto_iterations = st.slider("It√©rations automatiques", 500, 2000, 1000, 100, 
                                          help="Nombre d'it√©rations pour chaque type de forme.")
    
    # ============================================
    # NOUVELLES FONCTIONNALIT√âS : POST-TRAITEMENT DU NUAGE DE POINTS
    # ============================================
    st.subheader("üîß Post-traitement du Nuage de Points")
    
    # Algorithme 1: Reconstruction des nuages de points manquants
    enable_missing_reconstruction = st.checkbox("üîÑ Reconstruction des zones manquantes", value=False, key="enable_missing_reconstruction", 
                                               help="Utilise l'interpolation et le remplissage de trous pour reconstruire les zones manquantes du nuage de points.")
    
    # Algorithme 2: Nettoyage des artefacts et d√©formations
    enable_artifact_cleaning = st.checkbox("üßπ Nettoyage des artefacts et d√©formations", value=False, key="enable_artifact_cleaning", 
                                          help="Supprime les outliers, r√©duit le bruit et corrige les d√©formations mineures du nuage de points.")
    
    # Algorithme 3: Correction des d√©formations g√©om√©triques
    enable_geometric_correction = st.checkbox("üìê Correction des d√©formations g√©om√©triques", value=False, key="enable_geometric_correction", 
                                             help="Applique des algorithmes de lissage et d'optimisation pour corriger les d√©formations g√©om√©triques.")
    
    # ============================================
    # SECTION: VISUALISATION AVANC√âE DU MAILLAGE
    # ============================================
    st.subheader("üï∏Ô∏è Visualisation Avanc√©e du Maillage (Style Blender)")
    
    with st.expander("üé® Options de Visualisation Topologique", expanded=False):
        st.markdown("""
        **Visualisation professionnelle** comme dans Blender pour analyser la qualit√© du maillage:
        - **Wireframe**: Voir la structure des triangles/polygones
        - **UV Checker**: Grille damier pour v√©rifier le mapping de textures
        - **Subdivision**: Lisser la surface avec plus de g√©om√©trie
        - **Normales**: Visualiser l'orientation des surfaces
        """)
        
        col_w1, col_w2 = st.columns(2)
        
        with col_w1:
            wireframe_overlay = st.checkbox(
                "üï∏Ô∏è Afficher Wireframe (Fil de fer)", 
                value=False,
                help="Superpose le maillage en fil de fer pour voir la topologie exacte"
            )
            
            if wireframe_overlay:
                wireframe_thickness = st.slider(
                    "√âpaisseur du wireframe",
                    min_value=0.5,
                    max_value=3.0,
                    value=1.0,
                    step=0.5,
                    help="√âpaisseur des lignes du wireframe"
                )
            
            show_uv_checker = st.checkbox(
                "üé® UV Checker Pattern",
                value=False,
                help="Applique une texture damier pour visualiser la qualit√© du mapping UV"
            )
            
            show_topology_info = st.checkbox(
                "üìä Afficher Info Topologie",
                value=False,
                help="Statistiques d√©taill√©es: nombre de triangles, vertices, edges, qualit√©"
            )
        
        with col_w2:
            subdivision_level = st.slider(
                "üî∫ Niveau de Subdivision",
                min_value=0,
                max_value=3,
                value=0,
                help="Subdivise le maillage pour plus de lissage (0=d√©sactiv√©, 3=tr√®s lisse)"
            )
            
            show_normals = st.checkbox(
                "‚û°Ô∏è Visualiser les Normales",
                value=False,
                help="Affiche les vecteurs normaux pour chaque face (orientation des surfaces)"
            )
            
            normal_length = 0.05  # Valeur par d√©faut
            if show_normals:
                normal_length = st.slider(
                    "Longueur des normales",
                    min_value=0.01,
                    max_value=0.2,
                    value=0.05,
                    step=0.01,
                    format="%.2f",
                    help="Taille des fl√®ches de normales"
                )

    # ============================================
    # NOUVELLE SECTION: ANALYSE INTELLIGENTE PBR
    # ============================================
    st.header("ü§ñ Analyse IA de Sc√®ne + Suggestions PBR")
    
    if PBR_ANALYZER_AVAILABLE:
        st.markdown("""
        **Intelligence artificielle avanc√©e** pour identifier automatiquement les mat√©riaux 
        de votre sc√®ne et sugg√©rer les **textures PBR** n√©cessaires pour un rendu ultra-r√©aliste.
        
        üî¨ **Technologies utilis√©es:**
        - **CLIP** (OpenAI) : Vision par ordinateur pour classification de sc√®ne
        - **Phi-1.5** (Microsoft) : Mod√®le de langage pour recommandations intelligentes
        """)
        
        analyze_scene_btn = st.checkbox("üîç Activer l'analyse automatique de sc√®ne", value=False, key="analyze_scene_btn", 
                                       help="Analyse vos images pour sugg√©rer les textures PBR √† t√©l√©charger")
        
        # Checkbox pour injection automatique de textures
        enable_auto_injection = st.checkbox(
            "üíâ Injection automatique de textures depuis la biblioth√®que",
            value=False,
            help="T√©l√©charge et applique automatiquement les textures PBR bas√©es sur l'analyse IA"
        )
        st.session_state['enable_auto_texture_injection'] = enable_auto_injection
        
        if analyze_scene_btn and uploaded_files:
            with st.expander("üìä R√©sultats de l'analyse IA", expanded=True):
                with st.spinner("ü§ñ Analyse en cours avec CLIP + Phi-1.5..."):
                    try:
                        # Initialisation de l'analyseur
                        pbr_analyzer = TexturePBRAnalyzer(device=device)  # type: ignore
                        
                        # Conversion des fichiers upload√©s en images PIL
                        temp_images = []
                        for uploaded_file in uploaded_files[:5]:  # Limite √† 5 images pour performance
                            img = Image.open(uploaded_file).convert('RGB')
                            temp_images.append(img)
                        
                        # Analyse compl√®te
                        analysis_report = pbr_analyzer.analyze_scene_batch(temp_images)
                        
                        # INJECTION AUTOMATIQUE DE TEXTURES depuis la biblioth√®que locale
                        if st.session_state.get('enable_auto_texture_injection', False) and TEXTURE_MANAGER_AVAILABLE:
                            try:
                                texture_manager = st.session_state.get('texture_manager')
                                if texture_manager:
                                    dominant_material = analysis_report['top_materials'][0]['material'] if analysis_report['top_materials'] else 'unknown'
                                    
                                    # Rechercher texture correspondante
                                    best_texture = texture_manager.get_texture_for_injection(dominant_material)
                                    
                                    if best_texture:
                                        st.session_state['auto_injected_texture'] = best_texture
                                        st.success(f"‚úÖ Texture auto-inject√©e: {best_texture['name']}")
                                    else:
                                        st.info(f"‚ÑπÔ∏è Pas de texture locale pour '{dominant_material}'. T√©l√©chargez-en d'abord dans la biblioth√®que.")
                            except Exception as e:
                                st.warning(f"Injection auto d√©sactiv√©e: {e}")
                        
                        # Affichage des r√©sultats
                        col_a, col_b = st.columns(2)
                        
                        with col_a:
                            st.subheader("üé¨ Type de Sc√®ne D√©tect√©")
                            st.success(f"**{analysis_report['dominant_scene_type']}**")
                            st.metric("Confiance", f"{analysis_report['scene_confidence']*100:.1f}%")
                        
                        with col_b:
                            st.subheader("üß± Mat√©riaux Identifi√©s")
                            for mat_info in analysis_report['top_materials']:
                                st.write(f"- **{mat_info['material']}** ({mat_info['confidence']*100:.0f}%)")
                        
                        st.markdown("---")
                        st.subheader("üì¶ Textures PBR Recommand√©es")
                        
                        recommendations = analysis_report['texture_recommendations']
                        
                        if 'pbr_textures_needed' in recommendations:
                            textures = recommendations['pbr_textures_needed']
                            st.info(f"**{len(textures)} textures PBR** identifi√©es comme n√©cessaires:")
                            
                            # Affichage en colonnes
                            cols = st.columns(3)
                            for idx, texture in enumerate(textures):
                                with cols[idx % 3]:
                                    st.code(texture, language="")
                        
                        st.markdown("---")
                        st.subheader("üåê Liens de T√©l√©chargement (Gratuit)")
                        
                        for idx, link in enumerate(analysis_report['download_links']):
                            with st.expander(f"üìö {link['name']} - {link['license']}", expanded=False):
                                st.markdown(f"**Description:** {link['description']}")
                                st.markdown(f"**URL:** [{link['url']}]({link['url']})")
                                
                                if link['search_keywords']:
                                    st.markdown("**Mots-cl√©s de recherche:**")
                                    st.write(", ".join(link['search_keywords']))
                                
                                # BOUTON T√âL√âCHARGEMENT INDIVIDUEL pour chaque source
                                st.markdown("---")
                                if TEXTURE_MANAGER_AVAILABLE:
                                    button_key = f"download_from_{link['name'].replace(' ', '_')}_{idx}"
                                    if st.button(f"üöÄ T√©l√©charger depuis {link['name']}", key=button_key, type="primary"):
                                        with st.spinner(f"üì• T√©l√©chargement depuis {link['name']}..."):
                                            try:
                                                # Initialiser le gestionnaire si n√©cessaire
                                                if 'texture_manager' not in st.session_state:
                                                    st.session_state['texture_manager'] = TextureDownloadManager(storage_path="./texture_library")  # type: ignore
                                                
                                                texture_manager = st.session_state['texture_manager']
                                                
                                                # T√©l√©charger avec les mots-cl√©s sp√©cifiques de ce lien
                                                keywords = link.get('search_keywords', [])
                                                if keywords:
                                                    downloaded_ids = texture_manager.batch_download(
                                                        material_keywords=keywords,
                                                        max_textures=3,
                                                        resolution="2k"
                                                    )
                                                    
                                                    if downloaded_ids:
                                                        st.success(f"‚úÖ {len(downloaded_ids)} textures t√©l√©charg√©es depuis {link['name']}! Voir la biblioth√®que ci-dessous.")
                                                        st.session_state['auto_downloaded'] = True
                                                        st.rerun()
                                                    else:
                                                        st.warning(f"‚ö†Ô∏è Aucune texture trouv√©e pour {', '.join(keywords)}.")
                                                else:
                                                    st.warning("‚ö†Ô∏è Pas de mots-cl√©s disponibles pour cette source.")
                                            
                                            except Exception as e:
                                                st.error(f"‚ùå Erreur de t√©l√©chargement: {e}")
                        
                        # Sauvegarde du rapport
                        st.download_button(
                            label="üíæ T√©l√©charger le rapport complet (JSON)",
                            data=json.dumps(analysis_report, indent=2),
                            file_name=f"pbr_analysis_{uuid.uuid4().hex[:8]}.json",
                            mime="application/json"
                        )
                        
                        # ============================================
                        # G√âN√âRATION PIPELINE PBR AUTOMATIQUE
                        # ============================================
                        if AUTO_PBR_MAPPER_AVAILABLE:
                            st.markdown("---")
                            st.subheader("‚ö° Pipeline PBR Automatique Temps R√©el")
                            
                            if st.button("üöÄ G√©n√©rer Configuration Pipeline Complet"):
                                with st.spinner("‚ö° G√©n√©ration du pipeline PBR temps r√©el..."):
                                    try:
                                        # Donn√©es fictives pour d√©mo (seront remplac√©es par vraies donn√©es apr√®s reconstruction)
                                        dummy_vertices = np.random.rand(1000, 3)
                                        dummy_normals = np.random.rand(1000, 3)
                                        dummy_normals = dummy_normals / np.linalg.norm(dummy_normals, axis=1, keepdims=True)
                                        
                                        # G√©n√©ration du pipeline complet
                                        material_scores_dict = {mat['material']: mat['confidence'] for mat in analysis_report['top_materials']}
                                        
                                        pipeline_config = generate_complete_pbr_pipeline(  # type: ignore
                                            material_scores_dict,
                                            analysis_report['dominant_scene_type'],
                                            dummy_vertices,
                                            dummy_normals,
                                            device
                                        )
                                        
                                        # Affichage de la configuration
                                        col_pip1, col_pip2 = st.columns(2)
                                        
                                        with col_pip1:
                                            st.success("‚úÖ Pipeline PBR G√©n√©r√© !")
                                            st.json(pipeline_config['pbr_configuration'])
                                        
                                        with col_pip2:
                                            st.info("üéÆ Configuration Rendu Temps R√©el")
                                            st.json(pipeline_config['realtime_rendering'])
                                        
                                        st.markdown("---")
                                        st.subheader("üìê Strat√©gie UV Unwrap")
                                        st.json(pipeline_config['uv_unwrap_strategy'])
                                        
                                        st.markdown("---")
                                        st.metric("R√©solution Texture Recommand√©e", f"{pipeline_config['texture_resolution']}x{pipeline_config['texture_resolution']}")
                                        
                                        # Export de la configuration
                                        st.download_button(
                                            label="üíæ T√©l√©charger Config Pipeline (JSON)",
                                            data=json.dumps(pipeline_config, indent=2),
                                            file_name=f"pipeline_config_{uuid.uuid4().hex[:8]}.json",
                                            mime="application/json"
                                        )
                                        
                                        st.success("üéâ Pipeline pr√™t pour int√©gration Unreal/Unity/Blender !")
                                        
                                    except Exception as e:
                                        st.error(f"‚ùå Erreur g√©n√©ration pipeline: {e}")
                        
                        # ============================================
                        # FIN PIPELINE PBR AUTO
                        # ============================================
                        
                    except Exception as e:
                        st.error(f"‚ùå Erreur lors de l'analyse: {e}")
                        st.info("V√©rifiez que les mod√®les CLIP et Phi-1.5 sont correctement install√©s.")
        
        elif analyze_scene_btn and not uploaded_files:
            st.warning("‚ö†Ô∏è Veuillez d'abord charger des images pour l'analyse.")
    
    else:
        st.warning("‚ö†Ô∏è Module d'analyse PBR non disponible. V√©rifiez l'installation de texture_pbr_analyzer.py")
    
    # ============================================
    # FIN SECTION ANALYSE PBR
    # ============================================

    # ============================================
    # NOUVELLE SECTION: VFX IA INTELLIGENTS
    # ============================================
    st.header("üé¨ Effets VFX IA Automatiques")
    
    if VFX_ENGINE_AVAILABLE:
        st.markdown("""
        **Moteur VFX intelligent** qui applique automatiquement des effets r√©alistes :
        - ü™® Salet√© et usure selon gravit√©
        - ü¶Ä Rouille sur m√©tal (humidit√© + √¢ge)
        - üåø Mousse sur surfaces ombrag√©es
        - ‚ö° Usure g√©n√©rale (d√©coloration, fissures)
        
        **Plus besoin de Blender pour des effets r√©alistes !**
        """)
        
        apply_vfx = st.checkbox("üé¨ Activer VFX automatiques", value=False,
                               help="Applique des effets visuels intelligents sur votre mod√®le 3D")
        
        if apply_vfx:
            with st.expander("‚öôÔ∏è Param√®tres VFX", expanded=True):
                col_vfx1, col_vfx2 = st.columns(2)
                
                with col_vfx1:
                    vfx_intensity = st.slider("Intensit√© globale", 0.0, 1.0, 0.5, 0.05,
                                            help="Intensit√© de tous les effets")
                    vfx_age = st.slider("√Çge du mat√©riau", 0.0, 1.0, 0.3, 0.05,
                                      help="0=neuf, 1=tr√®s vieux")
                    vfx_humidity = st.slider("Humidit√©", 0.0, 1.0, 0.5, 0.05,
                                           help="0=sec, 1=tr√®s humide (rouille, mousse)")
                
                with col_vfx2:
                    vfx_exposure = st.slider("Exposition ext√©rieure", 0.0, 1.0, 0.5, 0.05,
                                           help="0=int√©rieur prot√©g√©, 1=ext√©rieur expos√©")
                    vfx_pollution = st.slider("Pollution", 0.0, 1.0, 0.3, 0.05,
                                            help="Niveau de salet√© environnementale")
                    
                    vfx_preset = st.selectbox("Pr√©r√©glages", [
                        "Personnalis√©",
                        "Neuf et propre",
                        "B√¢timent abandonn√©",
                        "Zone industrielle",
                        "Environnement forestier",
                        "D√©sert aride",
                        "Zone c√¥ti√®re"
                    ])
                
                # Application des pr√©r√©glages
                if vfx_preset == "Neuf et propre":
                    vfx_age, vfx_humidity, vfx_exposure, vfx_pollution = 0.1, 0.3, 0.2, 0.1
                elif vfx_preset == "B√¢timent abandonn√©":
                    vfx_age, vfx_humidity, vfx_exposure, vfx_pollution = 0.9, 0.7, 0.8, 0.6
                elif vfx_preset == "Zone industrielle":
                    vfx_age, vfx_humidity, vfx_exposure, vfx_pollution = 0.6, 0.5, 0.7, 0.9
                elif vfx_preset == "Environnement forestier":
                    vfx_age, vfx_humidity, vfx_exposure, vfx_pollution = 0.5, 0.9, 0.6, 0.3
                elif vfx_preset == "D√©sert aride":
                    vfx_age, vfx_humidity, vfx_exposure, vfx_pollution = 0.7, 0.1, 0.9, 0.4
                elif vfx_preset == "Zone c√¥ti√®re":
                    vfx_age, vfx_humidity, vfx_exposure, vfx_pollution = 0.6, 0.8, 0.8, 0.5
                
                # D√©tection automatique de mat√©riau
                auto_detect_material = st.checkbox("üîç D√©tection auto du mat√©riau", value=True,
                                                  help="L'IA d√©tecte le type de mat√©riau depuis les couleurs")
                
                manual_material = "concrete"  # Valeur par d√©faut
                if not auto_detect_material:
                    manual_material = st.selectbox("Type de mat√©riau", [
                        "concrete", "metal", "wood", "plastic", "stone", "glass"
                    ])
                
                st.info("üí° Les VFX seront appliqu√©s apr√®s la reconstruction 3D")
                
                # Stockage dans session state
                st.session_state.vfx_params = VFXParameters(  # type: ignore
                    intensity=vfx_intensity,
                    age=vfx_age,
                    humidity=vfx_humidity,
                    exposure=vfx_exposure,
                    pollution=vfx_pollution
                )
                st.session_state.vfx_auto_material = auto_detect_material
                st.session_state.vfx_manual_material = manual_material
        else:
            # D√©sactiver VFX
            if 'vfx_params' in st.session_state:
                del st.session_state.vfx_params
    
    else:
        st.warning("‚ö†Ô∏è Moteur VFX non disponible. V√©rifiez l'installation de intelligent_vfx_engine.py")
    
    # ============================================
    # FIN SECTION VFX
    # ============================================
    
    # ============================================
    # SECTION BIBLIOTH√àQUE (APR√àS ANALYSE)
    # ============================================
    st.markdown("---")
    st.header("üìö Biblioth√®que de Textures PBR (T√©l√©chargement & Injection Auto)")
    
    if TEXTURE_MANAGER_AVAILABLE:
        with st.expander("üîß G√©rer la biblioth√®que de textures", expanded=st.session_state.get('auto_downloaded', False)):
            try:
                # Initialisation du gestionnaire (sans cache pour √©viter probl√®mes de state)
                if 'texture_manager' not in st.session_state:
                    st.session_state['texture_manager'] = TextureDownloadManager(storage_path="./texture_library")  # type: ignore
                
                texture_manager = st.session_state['texture_manager']
                
                # Stats de la biblioth√®que
                stats = texture_manager.get_library_stats()
                col_stat1, col_stat2, col_stat3 = st.columns(3)
                with col_stat1:
                    st.metric("Textures t√©l√©charg√©es", stats['total_textures'])
                with col_stat2:
                    st.metric("Espace utilis√©", f"{stats['total_size_mb']:.1f} MB")
                with col_stat3:
                    st.metric("Types de mat√©riaux", len(stats['by_material']))
                
                st.markdown("**Mat√©riaux disponibles:**")
                if stats['by_material']:
                    for material, count in stats['by_material'].items():
                        st.write(f"- {material}: {count} texture(s)")
                
                st.markdown("---")
                
                # Recherche et t√©l√©chargement
                st.markdown("**üîç Rechercher et t√©l√©charger de nouvelles textures**")
                
                col_search1, col_search2 = st.columns([3, 1])
                with col_search1:
                    search_keywords = st.text_input(
                        "Mots-cl√©s (s√©par√©s par des virgules)",
                        value="concrete, metal, wood",
                        help="Ex: concrete, rusty metal, wooden planks"
                    )
                with col_search2:
                    resolution = st.selectbox("R√©solution", ["1k", "2k", "4k"], index=1)
                
                max_downloads = st.slider("Nombre max de textures √† t√©l√©charger", 1, 10, 3)
                
                if st.button("üöÄ Rechercher et T√©l√©charger", type="primary"):
                    keywords = [k.strip() for k in search_keywords.split(',')]
                    
                    with st.spinner(f"Recherche et t√©l√©chargement de textures {resolution}..."):
                        downloaded_ids = texture_manager.batch_download(
                            material_keywords=keywords,
                            max_textures=max_downloads,
                            resolution=resolution
                        )
                        
                        if downloaded_ids:
                            st.success(f"‚úÖ {len(downloaded_ids)} textures t√©l√©charg√©es avec succ√®s!")
                            st.rerun()
                        else:
                            st.warning("Aucune texture trouv√©e ou erreur de t√©l√©chargement.")
                
                st.markdown("---")
                
                # Aper√ßu des textures locales
                st.markdown("**üì¶ Textures disponibles localement**")
                
                filter_material = st.selectbox(
                    "Filtrer par mat√©riau",
                    ["Tous"] + list(stats['by_material'].keys()) if stats['by_material'] else ["Tous"]
                )
                
                local_textures = texture_manager.search_local_textures(
                    material_type=None if filter_material == "Tous" else filter_material
                )
                
                if local_textures:
                    st.write(f"**{len(local_textures)} texture(s) trouv√©e(s)**")
                    
                    # Afficher en grille de mini-cartes
                    num_cols = 3
                    for i in range(0, len(local_textures), num_cols):
                        cols = st.columns(num_cols)
                        
                        for j, col in enumerate(cols):
                            idx = i + j
                            if idx < len(local_textures):
                                tex = local_textures[idx]
                                
                                with col:
                                    # Mini carte
                                    with st.container():
                                        st.markdown(f"**{tex['name'][:30]}**")
                                        
                                        # Thumbnail si disponible
                                        if tex['thumbnail_path'] and Path(tex['thumbnail_path']).exists():
                                            try:
                                                img = Image.open(tex['thumbnail_path'])
                                                st.image(img, use_container_width=True)
                                            except:
                                                st.info("üì¶ Texture PBR")
                                        else:
                                            st.info("üì¶ Texture PBR")
                                        
                                        st.caption(f"Type: {tex['material_type']}")
                                        st.caption(f"R√©solution: {tex['resolution']}")
                                        st.caption(f"Maps: {len(tex['maps'])} fichiers")
                                        
                                        # Bouton d'injection manuelle
                                        if st.button(f"üíâ Injecter", key=f"inject_{tex['id']}"):
                                            st.session_state['manual_texture_injection'] = tex['id']
                                            st.info(f"Texture {tex['name']} s√©lectionn√©e pour injection!")
                else:
                    st.info("Aucune texture t√©l√©charg√©e. Utilisez la recherche ci-dessus pour en ajouter.")
            
            except Exception as e:
                st.error(f"Erreur biblioth√®que de textures: {e}")
                import traceback
                st.code(traceback.format_exc())
    else:
        st.warning("Module texture_download_manager non disponible")

    st.header("üñåÔ∏è Textures PBR Manuelles")
    texture_zip = st.file_uploader("Upload ZIP de textures PBR (dossiers par cat√©gorie e.g. rock/, water/)", type='zip', help="Les dossiers dans le ZIP d√©finissent les cat√©gories (ex: rock/albedo.png). Les textures sont int√©gr√©es dans une base FAISS pour correspondance dynamique.")
   
    if texture_zip is not None:
        with st.spinner("Traitement des textures PBR..."):
            with tempfile.TemporaryDirectory() as tmp_dir:
                zip_path = os.path.join(tmp_dir, 'textures.zip')
                with open(zip_path, 'wb') as f:
                    f.write(texture_zip.getbuffer())
                textures_dir = os.path.join(tmp_dir, 'textures')
                os.makedirs(textures_dir, exist_ok=True)
                with zipfile.ZipFile(zip_path, 'r') as z:
                    z.extractall(textures_dir)
                
                clip_model, clip_processor = load_clip_model()
                embeddings_list = []
                categories = []
                avg_colors_list = []
                db_path = os.path.join(tempfile.gettempdir(), 'streamlit_textures.db')
                conn = sqlite3.connect(db_path)  # type: ignore
                cur = conn.cursor()
                cur.execute('''CREATE TABLE IF NOT EXISTS textures
                               (category TEXT PRIMARY KEY, embedding BLOB, avg_color BLOB)''')
                if clip_model is not None:
                    for category in os.listdir(textures_dir):
                        cat_dir = os.path.join(textures_dir, category)
                        if os.path.isdir(cat_dir):
                            cat_images = []
                            for file in os.listdir(cat_dir):
                                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                                    img_path = os.path.join(cat_dir, file)
                                    image = Image.open(img_path).convert('RGB')
                                    cat_images.append(image)
                            if cat_images:
                                inputs = clip_processor(images=cat_images, return_tensors="pt").to(device)  # type: ignore
                                with torch.no_grad():
                                    embeddings = clip_model.get_image_features(**inputs)
                                    avg_emb = torch.mean(embeddings, dim=0).cpu().numpy()
                                all_pixels = []
                                for img in cat_images:
                                    img_np = np.array(img) / 255.0
                                    all_pixels.append(img_np.reshape(-1, 3))
                                if all_pixels:
                                    avg_color = np.mean(np.vstack(all_pixels), axis=0)
                                else:
                                    avg_color = np.array([0.5, 0.5, 0.5])
                                embeddings_list.append(avg_emb)
                                categories.append(category)
                                avg_colors_list.append(avg_color)
                                emb_blob = pickle.dumps(avg_emb)
                                color_blob = pickle.dumps(avg_color)
                                cur.execute("INSERT OR REPLACE INTO textures VALUES (?, ?, ?)", (category, emb_blob, color_blob))
                    
                    conn.commit()
                    
                    if embeddings_list:
                        # Am√©lioration : Seuil adaptatif bas√© sur variance des embeddings
                        emb_array = np.array(embeddings_list)
                        emb_std = np.std(emb_array)
                        adaptive_threshold_factor = 1.5  # Facteur pour tol√©rance dynamique
                        adaptive_max_dist = emb_std * adaptive_threshold_factor if emb_std > 0 else 2.0
                        st.info(f"Seuil adaptatif pour textures : {adaptive_max_dist:.2f} (bas√© sur std des embeddings = {emb_std:.2f})")
                        
                        # Cr√©ation de l'index avec fallback
                        try:
                            if FAISS_AVAILABLE:
                                dim = len(embeddings_list[0])
                                faiss_index = faiss.IndexFlatL2(dim)  # type: ignore
                                faiss_index.add(emb_array)  # type: ignore
                                st.session_state.search_index = faiss_index
                                st.session_state.is_faiss = True
                            else:
                                raise ImportError("FAISS non disponible")
                        except:
                            # Fallback sklearn
                            nn = NearestNeighbors(n_neighbors=1, metric='euclidean')
                            nn.fit(emb_array)
                            st.session_state.search_index = nn
                            st.session_state.is_faiss = False
                            st.info("Utilisation de scikit-learn NearestNeighbors comme fallback pour FAISS.")
                        
                        texture_metadata = [{'category': cat, 'avg_color': avg_col} for cat, avg_col in zip(categories, avg_colors_list)]
                        st.session_state.texture_metadata = texture_metadata
                        st.session_state.adaptive_max_dist = adaptive_max_dist
                        st.success(f"Textures PBR charg√©es: {len(categories)} cat√©gories int√©gr√©es (avec fallback si besoin) et sauvegard√©es en SQLite3.")
                        
                        # Affichage de la liste des types de textures dans un tableau depuis SQLite3
                        cur.execute("SELECT category FROM textures")
                        db_categories = [row[0] for row in cur.fetchall()]
                        df = pd.DataFrame({'Types de Textures': db_categories})
                        st.table(df)

                        # Affichage compact des textures PBR avec miniatures
                        if 'texture_metadata' in st.session_state and st.session_state.texture_metadata:
                            st.header("üé® Aper√ßu des Textures PBR")
                            for tex in st.session_state.texture_metadata:
                                category = tex['category']
                                avg_color = (tex['avg_color'] * 255).astype(int)
                                img_preview = Image.new('RGB', (50, 50), tuple(avg_color))
                                
                                col1, col2 = st.columns([1, 1])
                                with col1:
                                    st.markdown(f"**{category}**")
                                with col2:
                                    st.image(img_preview, width=50)
                        
                        # Bouton pour injecter les textures au rendu 3D
                        if st.button("Injecter les Textures au Rendu 3D de la Visionneuse Open3D"):
                            st.session_state.inject_textures = True
                            st.rerun()
                    else:
                        st.warning("Aucune cat√©gorie de textures valide trouv√©e dans le ZIP.")
                else:
                    st.warning("Mod√®le CLIP non disponible pour le traitement des textures.")
                conn.close()
   
    process_btn = st.button("üöÄ Lancer la Reconstruction 3D", type="primary")

with col2:
    if uploaded_files and len(uploaded_files) >= 2 and process_btn:
        start_time = time.time()  # Pour metric temps
        model = load_dust3r_model() if model_choice == "DUSt3R" else None
        if model is None:
            st.error("Impossible de charger le mod√®le s√©lectionn√©.")
        else:
            with st.spinner("Traitement en cours..."):
                try:
                    # Initialisation des widgets de progression avant le with
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    # Initialisation des variables pour √©viter les erreurs de scope
                    all_pts3d = []
                    all_colors = []
                    num_pairs = 0
                    loss_value = 0.0
                    
                    # Am√©lioration scalabilit√© : Note pour >10 images
                    if len(uploaded_files) > 10:
                        st.info("üí° Pour >10 images, envisagez un pr√©-filtrage COLMAP pour init poses (installez pycolmap si possible ; placeholder ci-dessous).")
                        # Placeholder COLMAP (comment√© ; d√©commentez si pycolmap install√©)
                        # import pycolmap
                        # ... (extraction features et matching COLMAP pour init)
                    
                    # Cr√©ation d'un r√©pertoire temporaire pour les images et tout le traitement dedans
                    with tempfile.TemporaryDirectory() as tmp_dir:
                        img_paths = []
                        for i, uploaded_file in enumerate(uploaded_files):
                            img_path = os.path.join(tmp_dir, f"img_{i:03d}.{uploaded_file.name.split('.')[-1]}")
                            with open(img_path, "wb") as f:
                                f.write(uploaded_file.getbuffer())
                            img_paths.append(img_path)

                       
                        if model_choice == "DUSt3R":
                            # Chargement des images DUSt3R ici (fichiers encore pr√©sents)
                            status_text.text("Chargement des images DUSt3R...")
                            images = dust3r_load_images(img_paths, size=512)
                           
                            status_text.text("Inf√©rence en cours...")
                            pairs = make_pairs(images, scene_graph='complete', prefilter=None, symmetrize=True)
                            output = inference(
                                pairs, model, device,
                                batch_size=batch_size
                            )
                           
                            progress_bar.progress(0.7)
                            status_text.text("Inf√©rence termin√©e ! Alignement global en cours...")
                           
                            # Toujours utiliser PointCloudOptimizer pour alignement coh√©rent, m√™me pour 2 images
                            mode = GlobalAlignerMode.PointCloudOptimizer
                            scene = global_aligner(
                                output,
                                device=device,
                                mode=mode
                            )
                           
                            loss = scene.compute_global_alignment(
                                init="mst",
                                niter=niter_align,
                                schedule='cosine',
                                lr=lr_align
                            )
                            loss_value = loss
                            progress_bar.progress(1.0)
                            status_text.text(f"Alignement termin√© ! Perte finale : {loss:.4f}")
                            # Test suggestion : V√©rifiez loss < 0.01 pour bonne qualit√©
                            if float(loss) > 0.01:  # type: ignore
                                st.warning("üí° Perte >0.01 ; essayez plus d'it√©rations ou images mieux √©clair√©es.")
                           
                            # R√©cup√©ration des r√©sultats DUSt3R
                            imgs = scene.imgs
                            poses = scene.get_im_poses()
                            pts3d = scene.get_pts3d()
                            if pts3d is None:
                                st.error('Erreur: pas de points 3D')
                                st.stop()
                            confidence_masks = scene.get_masks()
                           
                            # Initialisation des listes pour stocker les points et couleurs
                            all_pts3d = []
                            all_colors = []
                           
                            # Pr√©paration du nuage de points pour visualisation avec couleurs textur√©es
                            for i in range(len(imgs)):  # type: ignore
                                # Masque de confiance
                                conf_i = confidence_masks[i].detach().cpu().numpy()  # (H, W) = (512, 512)
                                pts3d_tensor = pts3d[i]

                                # Convertir pts3d en numpy et aplatir
                                if isinstance(pts3d_tensor, torch.Tensor):
                                    full_pts3d = pts3d_tensor.detach().cpu().numpy().reshape(-1, 3)
                                else:
                                    full_pts3d = pts3d_tensor.reshape(-1, 3)

                                # Ajuster la taille du masque pour correspondre aux points 3D
                                conf_mask_flat = conf_i.flatten()
                                if len(conf_mask_flat) > len(full_pts3d):  # type: ignore
                                    conf_mask_flat = conf_mask_flat[:len(full_pts3d)]
                                elif len(conf_mask_flat) < len(full_pts3d):
                                    full_pts3d = full_pts3d[:len(conf_mask_flat)]

                                # Appliquer le seuil et obtenir indices valides
                                conf_mask = conf_mask_flat > threshold_conf
                                valid_indices = np.flatnonzero(conf_mask)
                                pts3d_i = full_pts3d[valid_indices]

                                if len(pts3d_i) == 0:
                                    st.warning(f"Aucun point de confiance pour l'image {i+1}")
                                    continue

                                # Couleurs r√©alistes depuis imgs[i] (512 res, align√© parfaitement avec le masque)
                                # Assurer que img_np est en format (H, W, 3) pour l'extraction
                                img_tensor = imgs[i]  # type: ignore
                                if isinstance(img_tensor, torch.Tensor):
                                    img_np = img_tensor.detach().cpu().numpy()
                                else:
                                    img_np = img_tensor
                                img_np = np.array(img_np)
                                if img_np.shape[0] == 3:  # (C, H, W) -> transpose to (H, W, C)
                                    img_np = np.transpose(img_np, (1, 2, 0))
                                if img_np.max() > 1.0:
                                    img_np = img_np / 255.0

                                # Aplatir en (H*W, 3)
                                colors_full = img_np.reshape(-1, 3)[:len(conf_mask_flat)]

                                # Couleurs pour indices valides
                                colors_i = colors_full[valid_indices]

                                # Downsample si trop de points
                                n_valid = len(pts3d_i)
                                if n_valid > max_points_per_view:
                                    down_idx = np.random.choice(n_valid, max_points_per_view, replace=False)
                                    pts3d_i = pts3d_i[down_idx]
                                    colors_i = colors_i[down_idx]

                                all_pts3d.append(pts3d_i)
                                all_colors.append(colors_i)
                           
                            num_pairs = len(pairs)
                       
                        # Pas de perte pour MapAnything (feed-forward)
                   
                    # Fusion des nuages de points (apr√®s le with, mais arrays persistants)
                    if all_pts3d:
                        merged_pts3d = np.vstack(all_pts3d) * scale_factor
                        merged_colors = np.vstack(all_colors)
                        
                        # Appliquer g√©or√©f√©rencement si activ√©
                        if enable_georef and 'gps_data' in st.session_state and model_choice == "DUSt3R":
                            merged_pts3d = apply_georeferencing(merged_pts3d, poses, st.session_state['gps_data'], img_paths)  # type: ignore
                    else:
                        merged_pts3d = np.empty((0, 3))
                        merged_colors = np.empty((0, 3))

                    # Application dynamique des textures PBR si base disponible et injection activ√©e (avec seuil adaptatif)
                    matched_clusters = 0
                    if len(merged_pts3d) > 0 and 'inject_textures' in st.session_state and st.session_state.inject_textures and 'search_index' in st.session_state:
                        status_text.text("Application des textures PBR intelligentes...")
                        clip_model, clip_processor = load_clip_model()
                        if clip_model is not None:
                            # Clustering des couleurs pour classification efficace
                            n_clusters = min(50, len(merged_colors) // 100)
                            if n_clusters > 0:
                                kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
                                cluster_labels = kmeans.fit_predict(merged_colors)
                                cluster_centers = kmeans.cluster_centers_
                                enhanced_colors = merged_colors.copy()
                                max_distance_threshold = st.session_state.adaptive_max_dist  # Utilisation du seuil adaptatif
                                for c_id in range(n_clusters):
                                    center_rgb = cluster_centers[c_id]
                                    # Cr√©er un patch image rempli de la couleur du cluster
                                    patch = Image.new('RGB', (224, 224), color=tuple((center_rgb * 255).astype(int)))
                                    inputs = clip_processor(images=[patch], return_tensors="pt").to(device)  # type: ignore
                                    with torch.no_grad():
                                        emb = clip_model.get_image_features(**inputs).cpu().numpy().flatten()  # type: ignore
                                    # Recherche avec fallback
                                    if st.session_state.is_faiss:
                                        distances, indices = st.session_state.search_index.search(emb.reshape(1, -1), k=1)  # type: ignore
                                        dist = distances[0][0] if len(distances) > 0 else float('inf')
                                        idx = indices[0][0] if len(indices) > 0 and indices[0][0] != -1 else -1
                                    else:
                                        dist, idx = st.session_state.search_index.kneighbors(emb.reshape(1, -1), return_distance=True)  # type: ignore
                                        dist = dist[0][0]
                                        idx = idx[0][0]
                                    if idx != -1 and dist < max_distance_threshold:
                                        category = st.session_state.texture_metadata[idx]['category']
                                        # Utiliser la couleur moyenne stock√©e depuis SQLite3
                                        avg_texture_color = st.session_state.texture_metadata[idx]['avg_color']
                                        # Fusion r√©aliste : 70% couleur originale + 30% texture
                                        new_color = 0.7 * center_rgb + 0.3 * avg_texture_color
                                        # Appliquer au cluster
                                        mask = cluster_labels == c_id
                                        enhanced_colors[mask] = new_color
                                        matched_clusters += 1
                                merged_colors = enhanced_colors
                                if matched_clusters > 0:
                                    st.success(f"Textures PBR appliqu√©es dynamiquement via correspondances (seuil adaptatif {max_distance_threshold:.2f}). {matched_clusters}/{n_clusters} clusters match√©s.")
                                else:
                                    st.warning("Aucune zone de correspondance texture trouv√©e ; couleurs originales conserv√©es pour un rendu fid√®le.")
                            else:
                                st.warning("Aucun cluster g√©n√©r√© ; textures non appliqu√©es.")
                    elif 'inject_textures' in st.session_state and st.session_state.inject_textures:
                        st.info("Textures pr√™tes mais pas de points 3D disponibles pour l'injection.")
                    else:
                        st.info("Injection de textures non activ√©e.")
                   
                    st.success("Reconstruction termin√©e !")
                   
                    # Lib√©ration m√©moire GPU apr√®s traitement (plus agressif)
                    if device == 'cuda':
                        torch.cuda.empty_cache()
                        if torch.cuda.is_available():
                            st.info(f"M√©moire GPU lib√©r√©e : {torch.cuda.memory_reserved() / 1024**3:.1f} GB r√©serv√©e.")
                   
                    # Visualisation Open3D avec texture r√©aliste (fen√™tre externe)
                    if len(merged_pts3d) > 0:
                        st.info("üîì Ouvrant une fen√™tre Open3D externe pour la vue textur√©e du nuage de points...")
                        pcd = o3d.geometry.PointCloud()
                        pcd.points = o3d.utility.Vector3dVector(merged_pts3d)
                        pcd.colors = o3d.utility.Vector3dVector(merged_colors)
                        
                        # Ouvrir la fen√™tre Open3D imm√©diatement
                        o3d.visualization.draw_geometries(  # type: ignore
                            [pcd],
                            window_name=f"Nuage de Points 3D Textur√© - {model_choice}",
                            width=1600,
                            height=900,
                            left=100,
                            top=100,
                            point_show_normal=False
                        )
                        
                        # Analyse g√©om√©trique automatique RANSAC si activ√©e (apr√®s fermeture de la fen√™tre)
                        detected_shapes = {}
                        if enable_auto_ransac:
                            st.info("üî¨ Analyse g√©om√©trique automatique en cours...")
                            points = np.asarray(pcd.points)
                            modified_colors = merged_colors.copy()
                            
                            # D√©tection plan
                            try:
                                plane_model, plane_inliers = ransac_plane_detection(pcd, distance_threshold=ransac_auto_threshold, 
                                                                                   num_iterations=ransac_auto_iterations)
                                if len(plane_inliers) > len(points) * 0.1:  # Au moins 10% des points
                                    [a, b, c, d] = plane_model
                                    detected_shapes['plan'] = {"model": [a, b, c, d], "inliers": len(plane_inliers)}
                                    # Colorer inliers en rouge
                                    modified_colors[plane_inliers] = [1.0, 0.0, 0.0]  # Rouge
                                    st.success(f"Plan d√©tect√© automatiquement : {a:.3f}x + {b:.3f}y + {c:.3f}z + {d:.3f} = 0 ({len(plane_inliers)} points)")
                            except:
                                pass
                            
                            # D√©tection cylindre
                            try:
                                cyl_model, cyl_inliers = ransac_cylinder_detection(points, distance_threshold=ransac_auto_threshold, 
                                                                                  max_iterations=ransac_auto_iterations)
                                if cyl_model and len(cyl_inliers) > len(points) * 0.05:  # Au moins 5%
                                    detected_shapes['cylindre'] = {"model": cyl_model, "inliers": len(cyl_inliers)}
                                    # Colorer inliers en vert
                                    modified_colors[cyl_inliers] = [0.0, 1.0, 0.0]  # Vert
                                    st.success(f"Cylindre d√©tect√© : Rayon {cyl_model['radius']:.3f} ({len(cyl_inliers)} points)")
                            except:
                                pass
                            
                            # D√©tection sph√®re
                            try:
                                sph_model, sph_inliers = ransac_sphere_detection(points, distance_threshold=ransac_auto_threshold, 
                                                                                max_iterations=ransac_auto_iterations)
                                if sph_model and len(sph_inliers) > len(points) * 0.05:
                                    detected_shapes['sphere'] = {"model": sph_model, "inliers": len(sph_inliers)}
                                    # Colorer inliers en bleu
                                    modified_colors[sph_inliers] = [0.0, 0.0, 1.0]  # Bleu
                                    st.success(f"Sph√®re d√©tect√©e : Rayon {sph_model['radius']:.3f} ({len(sph_inliers)} points)")
                            except:
                                pass
                            
                            # Mettre √† jour les couleurs du nuage
                            pcd.colors = o3d.utility.Vector3dVector(modified_colors)
                            st.info("üé® Nuage color√© automatiquement : Rouge=Plans, Vert=Cylindres, Bleu=Sph√®res, Original=Autres")
                        
                        # ============================================
                        # POST-TRAITEMENT DU NUAGE DE POINTS
                        # ============================================
                        
                        # ============================================
                        # DOWNSAMPLING TEMPS R√âEL ULTRA-RAPIDE
                        # ============================================
                        if 'enable_realtime_downsampling' in st.session_state and st.session_state.enable_realtime_downsampling:
                            with st.spinner("‚ö° Application du downsampling temps r√©el ultra-rapide..."):
                                try:
                                    start_downsampling = time.time()
                                    original_points = len(np.asarray(pcd.points))
                                    
                                    # R√©cup√©ration des param√®tres
                                    target_points = getattr(st.session_state, 'downsampling_target', 100000)
                                    downsampling_strategy = getattr(st.session_state, 'downsampling_strategy', 'auto')
                                    preserve_colors = getattr(st.session_state, 'preserve_colors', True)
                                    preserve_normals = getattr(st.session_state, 'preserve_normals', False)
                                    
                                    # Application du pipeline de downsampling temps r√©el
                                    downsampled_pcd = apply_realtime_downsampling_pipeline(
                                        pcd, 
                                        target_points=target_points,
                                        strategy=downsampling_strategy,
                                        preserve_colors=preserve_colors,
                                        preserve_normals=preserve_normals
                                    )
                                    
                                    # Calcul des m√©triques
                                    final_points = len(np.asarray(downsampled_pcd.points))
                                    processing_time_ms = (time.time() - start_downsampling) * 1000
                                    compression_ratio = original_points / final_points if final_points > 0 else 0
                                    
                                    # Stockage des statistiques pour affichage
                                    st.session_state.realtime_downsampling_stats = {
                                        'original_points': original_points,
                                        'final_points': final_points,
                                        'processing_time_ms': processing_time_ms,
                                        'compression_ratio': compression_ratio,
                                        'target_achieved': final_points <= target_points * 1.1  # Tol√©rance 10%
                                    }
                                    
                                    # Mise √† jour du point cloud
                                    pcd = downsampled_pcd
                                    
                                    st.success(f"‚ö° Downsampling temps r√©el termin√© : {original_points:,} ‚Üí {final_points:,} points ({processing_time_ms:.1f}ms, {compression_ratio:.1f}x)")
                                    
                                except Exception as e:
                                    st.error(f"‚ùå Erreur downsampling temps r√©el : {e}")
                                    st.session_state.realtime_downsampling_stats = None
                        
                        # ============================================
                        # TRAITEMENT ML AVANC√â (POINTNET INSPIRED)
                        # ============================================
                        if 'enable_ml_processing' in st.session_state and st.session_state.enable_ml_processing:
                            with st.spinner("üß† Application du traitement ML avanc√© (PointNet-inspired)..."):
                                try:
                                    start_ml = time.time()
                                    
                                    # R√©cup√©ration des param√®tres ML
                                    ml_technique = getattr(st.session_state, 'ml_technique', "PointNet (Classification)")
                                    ml_task = getattr(st.session_state, 'ml_task', "Classification d'objets")
                                    ml_confidence_threshold = getattr(st.session_state, 'ml_confidence_threshold', 0.7)
                                    
                                    # Application de la classification PointNet-inspired
                                    if "PointNet" in ml_technique and "Classification" in ml_task:
                                        pcd_classified, ml_stats = apply_pointnet_classification(
                                            pcd, 
                                            confidence_threshold=ml_confidence_threshold
                                        )
                                        
                                        # Mise √† jour du point cloud
                                        pcd = pcd_classified
                                        
                                        # Stockage des statistiques
                                        st.session_state.ml_processing_stats = ml_stats
                                        
                                        # Affichage des r√©sultats
                                        processing_time_ml = (time.time() - start_ml) * 1000
                                        st.success(f"üß† Classification ML termin√©e : {ml_stats['classified_objects']:,} points classifi√©s ({processing_time_ml:.1f}ms)")
                                        
                                        # Distribution des classes
                                        class_names = ["Terrain", "B√¢timents", "V√©g√©tation", "V√©hicules", "Autres"]
                                        class_dist = ml_stats['class_distribution']
                                        
                                        st.info("üìä Distribution des classes :")
                                        for class_id, count in class_dist.items():
                                            if count > 0:
                                                percentage = (count / ml_stats['total_points']) * 100
                                                st.write(f"  ‚Ä¢ {class_names[class_id]} : {count:,} points ({percentage:.1f}%)")
                                    
                                    else:
                                        st.info(f"‚ö†Ô∏è Technique ML '{ml_technique}' pour t√¢che '{ml_task}' pas encore impl√©ment√©e (version simplifi√©e)")
                                        
                                except Exception as e:
                                    st.error(f"‚ùå Erreur traitement ML : {e}")
                                    st.session_state.ml_processing_stats = None
                        
                        # ============================================
                        # ANALYSE 4D TEMPORELLE (PY4DGEO-INSPIRED)
                        # ============================================
                        if 'enable_4d_analysis' in st.session_state and st.session_state.enable_4d_analysis:
                            with st.spinner("‚è∞ Analyse 4D temporelle en cours (M3C2)..."):
                                try:
                                    start_4d = time.time()
                                    
                                    # R√©cup√©ration des param√®tres 4D
                                    cylinder_radius = getattr(st.session_state, 'cylinder_radius', 0.1)
                                    min_points_cylinder = getattr(st.session_state, 'min_points_cylinder', 10)
                                    confidence_threshold_4d = getattr(st.session_state, 'confidence_threshold_4d', 0.95)
                                    max_distance_4d = getattr(st.session_state, 'max_distance_4d', 1.0)
                                    
                                    # Chargement des nuages de points temporels depuis les fichiers upload√©s
                                    reference_pcd = None
                                    comparison_pcd = None
                                    
                                    # R√©cup√©rer les fichiers depuis session_state
                                    ref_file = st.session_state.get('reference_pcd')
                                    comp_file = st.session_state.get('comparison_pcd')
                                    
                                    # Charger le nuage de r√©f√©rence
                                    if ref_file is not None:
                                        with tempfile.NamedTemporaryFile(delete=False, suffix='.ply') as tmp_file:
                                            tmp_file.write(ref_file.getbuffer())
                                            ref_path = tmp_file.name
                                        
                                        try:
                                            reference_pcd = o3d.io.read_point_cloud(ref_path)
                                            st.info(f"‚úÖ Nuage r√©f√©rence charg√© : {len(np.asarray(reference_pcd.points))} points")
                                        except Exception as e:
                                            st.error(f"Erreur chargement nuage r√©f√©rence : {e}")
                                        finally:
                                            os.unlink(ref_path)
                                    
                                    # Charger le nuage de comparaison
                                    if comp_file is not None:
                                        with tempfile.NamedTemporaryFile(delete=False, suffix='.ply') as tmp_file:
                                            tmp_file.write(comp_file.getbuffer())
                                            comp_path = tmp_file.name
                                        
                                        try:
                                            comparison_pcd = o3d.io.read_point_cloud(comp_path)
                                            st.info(f"‚úÖ Nuage comparaison charg√© : {len(np.asarray(comparison_pcd.points))} points")
                                        except Exception as e:
                                            st.error(f"Erreur chargement nuage comparaison : {e}")
                                        finally:
                                            os.unlink(comp_path)
                                    
                                    # V√©rifier que les deux nuages sont charg√©s
                                    if reference_pcd is None or comparison_pcd is None:
                                        st.error("‚ùå Les deux nuages de points temporels doivent √™tre fournis")
                                    else:
                                        # Application de l'analyse 4D
                                        change_pcd, stats_4d = apply_4d_change_detection(
                                            reference_pcd, 
                                            comparison_pcd,
                                            cylinder_radius=cylinder_radius,
                                            min_points=min_points_cylinder,
                                            confidence_threshold=confidence_threshold_4d,
                                            max_distance=max_distance_4d
                                        )
                                        
                                        if change_pcd is not None:
                                            # Mise √† jour du point cloud principal avec la carte de changements
                                            pcd = change_pcd
                                            
                                            # Stockage des statistiques
                                            st.session_state['4d_analysis_stats'] = stats_4d
                                            
                                            # Affichage des r√©sultats d√©taill√©s
                                            processing_time_4d = (time.time() - start_4d) * 1000
                                            st.success(f"‚è∞ Analyse 4D termin√©e : {stats_4d['erosion_points']} √©rosions, {stats_4d['deposition_points']} d√©p√¥ts ({processing_time_4d:.1f}ms)")
                                            
                                            # Affichage des m√©triques d√©taill√©es
                                            with st.expander("üìä R√©sultats D√©taill√©s de l'Analyse 4D", expanded=True):
                                                col1, col2 = st.columns(2)
                                                
                                                with col1:
                                                    st.markdown("**üî¥ √ârosions (Rouge)**")
                                                    st.write(f"‚Ä¢ Points √©rod√©s: {stats_4d['erosion_points']:,}")
                                                    st.write(f"‚Ä¢ Volume √©rod√©: {stats_4d['change_distribution']['erosion_volume']:.3f} m¬≥")
                                                    st.write(f"‚Ä¢ Magnitude max: {stats_4d['mean_change_magnitude']:.3f} m")
                                                    
                                                with col2:
                                                    st.markdown("**üîµ D√©p√¥ts (Bleu)**")
                                                    st.write(f"‚Ä¢ Points d√©pos√©s: {stats_4d['deposition_points']:,}")
                                                    st.write(f"‚Ä¢ Volume d√©pos√©: {stats_4d['change_distribution']['deposition_volume']:.3f} m¬≥")
                                                    st.write(f"‚Ä¢ Changement net: {stats_4d['change_distribution']['net_change']:.3f} m¬≥")
                                                    
                                                st.markdown("**üìà Statistiques Globales**")
                                                st.write(f"‚Ä¢ Points analys√©s: {stats_4d['total_points_analyzed']:,}")
                                                st.write(f"‚Ä¢ Points stables: {stats_4d['stable_points']:,}")
                                                st.write(f"‚Ä¢ Confiance moyenne: {stats_4d['confidence_stats']['mean']:.2f}")
                                                st.write(f"‚Ä¢ Seuil MAD: {stats_4d['mad_threshold']:.4f} m")
                                                
                                                # Graphique de distribution des changements
                                                change_magnitudes = []
                                                if stats_4d['erosion_points'] > 0:
                                                    change_magnitudes.extend([-stats_4d['mean_change_magnitude']] * min(stats_4d['erosion_points'], 100))
                                                if stats_4d['deposition_points'] > 0:
                                                    change_magnitudes.extend([stats_4d['mean_change_magnitude']] * min(stats_4d['deposition_points'], 100))
                                                    
                                                if change_magnitudes:
                                                    fig, ax = plt.subplots(figsize=(8, 4))
                                                    ax.hist(change_magnitudes, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
                                                    ax.axvline(x=0, color='red', linestyle='--', alpha=0.7, label='Seuil de changement')
                                                    ax.set_xlabel('Magnitude du Changement (m)')
                                                    ax.set_ylabel('Fr√©quence')
                                                    ax.set_title('Distribution des Changements D√©tect√©s')
                                                    ax.legend()
                                                    st.pyplot(fig)
                                                    
                                        else:
                                            st.error("‚ùå √âchec de l'analyse 4D")
                                            
                                except Exception as e:
                                    st.error(f"‚ùå Erreur analyse 4D : {e}")
                                    import traceback
                                    st.code(traceback.format_exc())
                                    st.session_state['4d_analysis_stats'] = None
                        
                        # Algorithme 1: Reconstruction des zones manquantes
                        if enable_missing_reconstruction:
                            with st.spinner("üîÑ Reconstruction des zones manquantes en cours..."):
                                try:
                                    # Utiliser Poisson reconstruction pour remplir les trous
                                    pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))
                                    mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=9)
                                    
                                    # Convertir le maillage en nuage de points dense
                                    sampled_pcd = mesh.sample_points_uniformly(number_of_points=len(np.asarray(pcd.points)) * 2)
                                    
                                    # Fusionner avec le nuage original
                                    combined_pcd = pcd + sampled_pcd
                                    
                                    # Supprimer les duplicatas
                                    combined_pcd.remove_duplicated_points()
                                    
                                    pcd = combined_pcd
                                    st.success(f"‚úÖ Reconstruction termin√©e : {len(np.asarray(pcd.points))} points (zones manquantes remplies)")
                                except Exception as e:
                                    st.error(f"‚ùå Erreur reconstruction : {e}")
                        
                        # Algorithme 2: Nettoyage des artefacts et d√©formations
                        if enable_artifact_cleaning:
                            with st.spinner("üßπ Nettoyage des artefacts en cours..."):
                                try:
                                    # Suppression des outliers statistiques
                                    pcd, ind = pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=2.0)
                                    st.info(f"Outliers statistiques supprim√©s : {len(ind)} points conserv√©s")
                                    
                                    # Suppression des outliers par rayon
                                    pcd, ind = pcd.remove_radius_outlier(nb_points=16, radius=0.05)
                                    st.info(f"Outliers par rayon supprim√©s : {len(ind)} points conserv√©s")
                                    
                                    # Lissage pour r√©duire le bruit
                                    pcd = pcd.filter_smooth_simple(number_of_iterations=1)
                                    
                                    st.success("‚úÖ Nettoyage termin√© : artefacts et bruit r√©duits")
                                except Exception as e:
                                    st.error(f"‚ùå Erreur nettoyage : {e}")
                        
                        # Algorithme 3: Correction des d√©formations g√©om√©triques
                        if enable_geometric_correction:
                            with st.spinner("üìê Correction des d√©formations g√©om√©triques en cours..."):
                                try:
                                    # Calcul des normales si pas d√©j√† fait
                                    if not pcd.has_normals():
                                        pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))
                                    
                                    # Lissage bilat√©ral pour corriger les d√©formations
                                    pcd = pcd.filter_smooth_taubin(number_of_iterations=10)
                                    
                                    # Correction des normales
                                    pcd.orient_normals_consistent_tangent_plane(k=15)
                                    
                                    st.success("‚úÖ Correction g√©om√©trique termin√©e : d√©formations liss√©es")
                                except Exception as e:
                                    st.error(f"‚ùå Erreur correction g√©om√©trique : {e}")
                        
                        # ============================================
                        # APPLICATION DES VFX IA INTELLIGENTS
                        # ============================================
                        if 'vfx_params' in st.session_state and VFX_ENGINE_AVAILABLE:
                            with st.spinner("üé¨ Application des effets VFX intelligents..."):
                                try:
                                    vfx_engine = IntelligentVFXEngine(device=device)  # type: ignore
                                    
                                    # D√©tection ou s√©lection du mat√©riau
                                    material_type = None
                                    if not st.session_state.vfx_auto_material:
                                        material_map = {
                                            "concrete": MaterialType.CONCRETE,  # type: ignore
                                            "metal": MaterialType.METAL,  # type: ignore
                                            "wood": MaterialType.WOOD,  # type: ignore
                                            "plastic": MaterialType.PLASTIC,  # type: ignore
                                            "stone": MaterialType.STONE,  # type: ignore
                                            "glass": MaterialType.GLASS,  # type: ignore
                                        }
                                        material_type = material_map.get(st.session_state.vfx_manual_material)
                                    
                                    # Application des VFX
                                    pcd = vfx_engine.apply_automatic_vfx(
                                        pcd,
                                        st.session_state.vfx_params,
                                        material_type
                                    )
                                    
                                    st.success("‚úÖ Effets VFX appliqu√©s avec succ√®s !")
                                    
                                    # G√©n√©ration des maps PBR
                                    if material_type:
                                        pbr_maps = vfx_engine.generate_pbr_maps(pcd, material_type)
                                        
                                        with st.expander("üìä Maps PBR G√©n√©r√©es"):
                                            st.write(f"**Albedo:** {len(pbr_maps['albedo'])} vertices")
                                            st.write(f"**Roughness:** Moyenne = {np.mean(pbr_maps['roughness']):.2f}")
                                            st.write(f"**Metallic:** Moyenne = {np.mean(pbr_maps['metallic']):.2f}")
                                            st.write(f"**AO:** Moyenne = {np.mean(pbr_maps['ao']):.2f}")
                                    
                                except Exception as e:
                                    st.error(f"‚ùå Erreur VFX: {e}")
                        # ============================================
                        # FIN APPLICATION VFX
                        # ============================================
                        
                        # Nuage de points avec options avanc√©es
                        o3d.visualization.draw_geometries(  # type: ignore
                            [pcd],
                            window_name=f"Nuage de Points 3D Textur√© - {model_choice}",
                            width=1600,
                            height=900,
                            left=100,
                            top=100,
                            point_show_normal=False
                        )
                        
                        # Bouton de t√©l√©chargement pour le nuage de points (Windows-safe)
                        pcd_tmp_path = os.path.join(tempfile.gettempdir(), f"temp_pcd_{uuid.uuid4().hex}.ply")
                        o3d.io.write_point_cloud(pcd_tmp_path, pcd)
                        time.sleep(0.1)  # Attente pour Windows
                        with open(pcd_tmp_path, "rb") as f:
                            pcd_bytes = f.read()
                        if os.path.exists(pcd_tmp_path):
                            os.remove(pcd_tmp_path)
                        st.download_button(
                            label="üì• T√©l√©charger Nuage de Points (.ply)",
                            data=pcd_bytes,
                            file_name=f"{model_choice}_pointcloud.ply",
                            mime="model/ply"
                        )
                        
                        # Export LAS pour topographie
                        if LAS_AVAILABLE:
                            las_bytes = export_to_las(merged_pts3d, merged_colors)
                            if las_bytes:
                                st.download_button(
                                    label="üì• T√©l√©charger Nuage de Points (.las)",
                                    data=las_bytes,
                                    file_name=f"{model_choice}_pointcloud.las",
                                    mime="application/octet-stream",
                                    help="Format LAS pour logiciels de topographie (CloudCompare, AutoCAD, etc.)"
                                )
                        else:
                            st.info("üí° Pour exporter en LAS (format standard LiDAR/topographie), installez laspy: `pip install laspy`")
                        
                        # ============================================
                        # D√âTECTION DE FORMES G√âOM√âTRIQUES AVEC RANSAC
                        # ============================================
                        st.header("üî¨ D√©tection de Formes G√©om√©triques avec RANSAC (Scientifique)")
                        
                        shape_type = st.selectbox("Type de forme √† d√©tecter", ["Plan", "Cylindre", "Sph√®re"], 
                                                 help="Utilise RANSAC pour d√©tecter des primitives g√©om√©triques dans le nuage de points (bas√© sur algorithmes scientifiques robustes au bruit).")
                        
                        ransac_distance_threshold = st.slider("Seuil de distance RANSAC", 0.005, 0.2, 0.02, 0.005, 
                                                             help="Tol√©rance pour consid√©rer un point comme inlier (plus petit = plus strict).")
                        
                        ransac_iterations = st.slider("Nombre d'it√©rations RANSAC", 100, 5000, 1000, 100, 
                                                     help="Plus d'it√©rations = plus pr√©cis mais plus lent. Recommand√©: 1000+ pour de gros nuages.")
                        
                        if st.button("üöÄ D√©tecter Forme avec RANSAC"):
                            with st.spinner("Analyse RANSAC en cours (algorithmes scientifiques)..."):
                                points = np.asarray(pcd.points)
                                
                                if shape_type == "Plan":
                                    plane_model, inliers = ransac_plane_detection(pcd, distance_threshold=ransac_distance_threshold, 
                                                                                  num_iterations=ransac_iterations)
                                    [a, b, c, d] = plane_model
                                    st.success(f"**Plan d√©tect√© (√©quation scientifique)** : {a:.4f}x + {b:.4f}y + {c:.4f}z + {d:.4f} = 0")
                                    st.metric("üìä Inliers d√©tect√©s", f"{len(inliers)} / {len(points)} points")
                                    
                                    # Visualisation scientifique
                                    inlier_cloud = pcd.select_by_index(inliers)
                                    outlier_cloud = pcd.select_by_index(inliers, invert=True)
                                    inlier_cloud.paint_uniform_color([1.0, 0, 0])  # Rouge pour inliers
                                    outlier_cloud.paint_uniform_color([0.6, 0.6, 0.6])  # Gris pour outliers
                                    o3d.visualization.draw_geometries([inlier_cloud, outlier_cloud],  # type: ignore
                                                                     window_name="D√©tection Plan RANSAC - Vue Scientifique")
                                    
                                    # Export segment√©
                                    inlier_ply_path = os.path.join(tempfile.gettempdir(), f"ransac_plane_{uuid.uuid4().hex}.ply")
                                    o3d.io.write_point_cloud(inlier_ply_path, inlier_cloud)
                                    with open(inlier_ply_path, "rb") as f:
                                        st.download_button("üì• T√©l√©charger Plan D√©tect√© (.ply)", 
                                                         data=f.read(), 
                                                         file_name="ransac_plane.ply",
                                                         mime="model/ply")
                                
                                elif shape_type == "Cylindre":
                                    model, inliers = ransac_cylinder_detection(points, distance_threshold=ransac_distance_threshold, 
                                                                              max_iterations=ransac_iterations)
                                    if model and len(inliers) > 10:
                                        st.success(f"**Cylindre d√©tect√©** : Rayon = {model['radius']:.4f}, Axe = [{model['axis'][0]:.4f}, {model['axis'][1]:.4f}, {model['axis'][2]:.4f}], Centre = [{model['center'][0]:.4f}, {model['center'][1]:.4f}, {model['center'][2]:.4f}]")
                                        st.metric("üìä Inliers d√©tect√©s", f"{len(inliers)} / {len(points)} points")
                                        
                                        # Visualisation
                                        inlier_cloud = pcd.select_by_index(inliers)
                                        outlier_cloud = pcd.select_by_index(inliers, invert=True)
                                        inlier_cloud.paint_uniform_color([0, 1.0, 0])  # Vert
                                        outlier_cloud.paint_uniform_color([0.6, 0.6, 0.6])
                                        o3d.visualization.draw_geometries([inlier_cloud, outlier_cloud],  # type: ignore
                                                                         window_name="D√©tection Cylindre RANSAC")
                                        
                                        # Export
                                        cyl_ply_path = os.path.join(tempfile.gettempdir(), f"ransac_cylinder_{uuid.uuid4().hex}.ply")
                                        o3d.io.write_point_cloud(cyl_ply_path, inlier_cloud)
                                        with open(cyl_ply_path, "rb") as f:
                                            st.download_button("üì• T√©l√©charger Cylindre D√©tect√© (.ply)", 
                                                             data=f.read(), 
                                                             file_name="ransac_cylinder.ply",
                                                             mime="model/ply")
                                    else:
                                        st.error("‚ùå Aucun cylindre fiable d√©tect√©. Essayez d'ajuster les param√®tres ou v√©rifiez les donn√©es.")
                                
                                elif shape_type == "Sph√®re":
                                    model, inliers = ransac_sphere_detection(points, distance_threshold=ransac_distance_threshold, 
                                                                            max_iterations=ransac_iterations)
                                    if model and len(inliers) > 10:
                                        st.success(f"**Sph√®re d√©tect√©e** : Centre = [{model['center'][0]:.4f}, {model['center'][1]:.4f}, {model['center'][2]:.4f}], Rayon = {model['radius']:.4f}")
                                        st.metric("üìä Inliers d√©tect√©s", f"{len(inliers)} / {len(points)} points")
                                        
                                        # Visualisation
                                        inlier_cloud = pcd.select_by_index(inliers)
                                        outlier_cloud = pcd.select_by_index(inliers, invert=True)
                                        inlier_cloud.paint_uniform_color([0, 0, 1.0])  # Bleu
                                        outlier_cloud.paint_uniform_color([0.6, 0.6, 0.6])
                                        o3d.visualization.draw_geometries([inlier_cloud, outlier_cloud],  # type: ignore
                                                                         window_name="D√©tection Sph√®re RANSAC")
                                        
                                        # Export
                                        sph_ply_path = os.path.join(tempfile.gettempdir(), f"ransac_sphere_{uuid.uuid4().hex}.ply")
                                        o3d.io.write_point_cloud(sph_ply_path, inlier_cloud)
                                        with open(sph_ply_path, "rb") as f:
                                            st.download_button("üì• T√©l√©charger Sph√®re D√©tect√©e (.ply)", 
                                                             data=f.read(), 
                                                             file_name="ransac_sphere.ply",
                                                             mime="model/ply")
                                    else:
                                        st.error("‚ùå Aucune sph√®re fiable d√©tect√©e. Essayez d'ajuster les param√®tres.")
                        
                        # Maillage si demand√© (optimis√© pour r√©alisme haute qualit√©)
                        if generate_mesh:
                            try:
                                st.info(f"üîì G√©n√©rant et ouvrant fen√™tre pour le maillage 3D ultra-r√©aliste avec {mesh_method}...")

                                # V√©rification si nuage de points suffisant pour maillage
                                if len(pcd.points) < 1000:
                                    st.warning("‚ö†Ô∏è Aucune g√©om√©trie trouv√©e : le nuage de points est trop sparse pour g√©n√©rer un maillage.")
                                else:
                                    # VOXEL GRID FILTERING AVANC√â - Optimisation bas√©e sur l'article Medium
                                    with st.spinner("üîß Voxel Grid Filtering avanc√© pour optimisation..."):

                                        # Analyse de la densit√© du nuage pour voxel size adaptatif
                                        points = np.asarray(pcd.points)
                                        if len(points) > 10000:
                                            # Calcul de la densit√© locale pour optimisation adaptative
                                            pcd_tree = o3d.geometry.KDTreeFlann(pcd)
                                            densities = []

                                            # √âchantillonnage pour performance (1 point sur 100)
                                            sample_indices = np.random.choice(len(points),
                                                                            min(1000, len(points)//100),
                                                                            replace=False)

                                            for idx in sample_indices:
                                                _, _, distances = pcd_tree.search_knn_vector_3d(points[idx], 50)
                                                if len(distances) > 1:
                                                    # Densit√© = 1 / distance moyenne au carr√©
                                                    avg_distance = np.mean(distances[1:])  # Exclure le point lui-m√™me
                                                    density = 1.0 / (avg_distance ** 2) if avg_distance > 0 else 0
                                                    densities.append(density)

                                            if densities:
                                                avg_density = np.mean(densities)
                                                std_density = np.std(densities)

                                                # Ajustement adaptatif du voxel size selon la densit√©
                                                if mesh_quality_preset == "Ultra HD":
                                                    # Pour Ultra HD, garder plus de d√©tails m√™me dans zones denses
                                                    adaptive_voxel_size = mesh_voxel_size * max(0.5, 1.0 - (avg_density / (avg_density + std_density)))
                                                elif mesh_quality_preset == "High":
                                                    adaptive_voxel_size = mesh_voxel_size * max(0.7, 1.0 - (avg_density / (avg_density + 2*std_density)))
                                                else:  # Standard
                                                    adaptive_voxel_size = mesh_voxel_size * max(0.8, 1.0 - (avg_density / (avg_density + 3*std_density)))

                                                st.info(f"üéØ Voxel Grid Filtering adaptatif : {mesh_voxel_size:.4f} ‚Üí {adaptive_voxel_size:.4f} (densit√©: {avg_density:.2f})")
                                                mesh_voxel_size = adaptive_voxel_size

                                        # Application du voxel downsampling optimis√©
                                        pcd_down = pcd.voxel_down_sample(voxel_size=mesh_voxel_size)

                                        # M√©triques de performance du voxel filtering
                                        reduction_ratio = len(pcd_down.points) / len(pcd.points)

                                        # Stocker les statistiques pour affichage
                                        st.session_state.current_pcd_stats = {
                                            'original_points': len(pcd.points),
                                            'voxel_points': len(pcd_down.points),
                                            'reduction_ratio': reduction_ratio,
                                            'voxel_size_used': mesh_voxel_size
                                        }

                                        st.info(f"‚ö° Voxel Grid Filtering : {len(pcd.points):,} ‚Üí {len(pcd_down.points):,} points ({reduction_ratio:.1%} conserv√©)")

                                        # Filtrage statistique suppl√©mentaire pour qualit√©
                                        if mesh_clean_artifacts and len(pcd_down.points) > 1000:
                                            # Calcul des distances inter-points pour d√©tecter les outliers
                                            pcd_tree_down = o3d.geometry.KDTreeFlann(pcd_down)
                                            distances = []

                                            for i in range(len(pcd_down.points)):
                                                _, _, dist = pcd_tree_down.search_knn_vector_3d(pcd_down.points[i], 10)
                                                if len(dist) > 1:
                                                    distances.append(np.mean(dist[1:]))  # Distance moyenne aux 9 plus proches voisins

                                            if distances:
                                                distances = np.array(distances)
                                                mean_dist = np.mean(distances)
                                                std_dist = np.std(distances)

                                                # Seuil statistique pour filtrage des outliers (comme dans l'article)
                                                outlier_threshold = mean_dist + 2 * std_dist

                                                # Cr√©er masque pour conserver seulement les points "normaux"
                                                keep_mask = distances <= outlier_threshold
                                                pcd_down = pcd_down.select_by_index(np.where(keep_mask)[0])

                                                st.info(f"üßπ Filtrage statistique : conserv√© {np.sum(keep_mask)}/{len(keep_mask)} points (seuil: {outlier_threshold:.4f})")

                                        # Mise √† jour des statistiques apr√®s nettoyage
                                        final_points = len(pcd_down.points)
                                        final_reduction = final_points / len(pcd.points)
                                        st.session_state.current_pcd_stats.update({
                                            'final_points': final_points,
                                            'final_reduction_ratio': final_reduction,
                                            'outliers_removed': st.session_state.current_pcd_stats['voxel_points'] - final_points
                                        })

                                    # ============================================
                                    # DOWNSAMPLING ULTRA-RAPIDE TEMPS R√âEL (Inspired by Sohail Saifi)
                                    # Pipeline 10M ‚Üí 100K points en millisecondes
                                    # ============================================
                                    with st.spinner("‚ö° Downsampling Ultra-Rapide - Pipeline Temps R√©el..."):

                                        # √âtape 1: Analyse du volume de donn√©es et strat√©gie adaptative
                                        n_points = len(pcd.points)
                                        target_points = st.session_state.get('downsampling_target', 100000)  # 100K par d√©faut

                                        # Strat√©gies selon la taille du nuage
                                        if n_points > 10000000:  # > 10M points
                                            strategy = "ultra_fast"  # Pipeline ultra-rapide
                                            st.info(f"üöÄ Pipeline Ultra-Rapide activ√© : {n_points:,} ‚Üí {target_points:,} points")
                                        elif n_points > 1000000:  # > 1M points
                                            strategy = "fast"  # Pipeline rapide
                                            st.info(f"‚ö° Pipeline Rapide activ√© : {n_points:,} ‚Üí {target_points:,} points")
                                        else:  # < 1M points
                                            strategy = "quality"  # Pipeline qualit√©
                                            st.info(f"üéØ Pipeline Qualit√© activ√© : {n_points:,} ‚Üí {target_points:,} points")

                                        start_time = time.time()

                                        # √âtape 2: Pr√©-downsampling par voxel pour gros volumes
                                        if n_points > 5000000:  # > 5M points
                                            # Voxel agressif pour r√©duire rapidement
                                            pre_voxel_size = np.cbrt((n_points / 1000000)) * 0.01  # Adaptatif
                                            pcd = pcd.voxel_down_sample(voxel_size=pre_voxel_size)
                                            st.info(f"üî≤ Pr√©-downsampling voxel : {n_points:,} ‚Üí {len(pcd.points):,} points")

                                        # √âtape 3: Pipeline de downsampling multi-√©tapes
                                        current_points = len(pcd.points)

                                        # 3.1 Random Sampling (ultra-rapide pour gros volumes)
                                        if strategy == "ultra_fast" and current_points > target_points * 2:
                                            random_sample = min(target_points * 2, current_points)
                                            indices = np.random.choice(current_points, random_sample, replace=False)
                                            pcd = pcd.select_by_index(indices)
                                            st.info(f"üé≤ Random sampling : {current_points:,} ‚Üí {len(pcd.points):,} points")

                                        # 3.2 Uniform Grid Sampling (√©quilibr√©)
                                        current_points = len(pcd.points)
                                        if current_points > target_points * 1.5:
                                            # Cr√©er une grille uniforme dans l'espace
                                            points_array = np.asarray(pcd.points)
                                            bbox_min = np.min(points_array, axis=0)
                                            bbox_max = np.max(points_array, axis=0)
                                            bbox_size = bbox_max - bbox_min

                                            # Nombre de cellules par dimension pour atteindre target
                                            volume_ratio = target_points / current_points
                                            grid_cells = int(np.cbrt(1.0 / volume_ratio))
                                            grid_cells = max(2, min(50, grid_cells))  # Limiter entre 2 et 50

                                            # Assigner chaque point √† une cellule de grille
                                            grid_indices = np.floor((points_array - bbox_min) / (bbox_size / grid_cells)).astype(int)
                                            grid_indices = np.clip(grid_indices, 0, grid_cells - 1)

                                            # Cr√©er une cl√© unique pour chaque cellule
                                            grid_keys = grid_indices[:, 0] + grid_indices[:, 1] * grid_cells + grid_indices[:, 2] * grid_cells * grid_cells

                                            # S√©lectionner un point par cellule (le premier trouv√©)
                                            unique_keys, indices = np.unique(grid_keys, return_index=True)
                                            pcd = pcd.select_by_index(indices)

                                            st.info(f"üìê Uniform grid sampling : {current_points:,} ‚Üí {len(pcd.points):,} points ({grid_cells}¬≥ cellules)")

                                        # 3.3 Farthest Point Sampling (qualit√© optimale)
                                        current_points = len(pcd.points)
                                        if current_points > target_points:
                                            # Impl√©mentation optimis√©e du farthest point sampling
                                            points_array = np.asarray(pcd.points)

                                            # Initialisation avec un point al√©atoire
                                            selected_indices = [np.random.randint(0, current_points)]
                                            min_distances = np.full(current_points, np.inf)

                                            # S√©lection it√©rative des points les plus √©loign√©s
                                            while len(selected_indices) < target_points and len(selected_indices) < current_points:
                                                # Calculer distances au dernier point s√©lectionn√©
                                                last_point = points_array[selected_indices[-1]]
                                                distances = np.linalg.norm(points_array - last_point, axis=1)
                                                min_distances = np.minimum(min_distances, distances)

                                                # S√©lectionner le point le plus √©loign√©
                                                farthest_idx = np.argmax(min_distances)
                                                selected_indices.append(farthest_idx)

                                                # Mise √† jour des distances minimales
                                                if len(selected_indices) % 1000 == 0:  # Progress update
                                                    progress = len(selected_indices) / target_points
                                                    st.info(f"üéØ Farthest Point Sampling : {len(selected_indices)}/{target_points} points s√©lectionn√©s")

                                            pcd = pcd.select_by_index(selected_indices)
                                            st.info(f"üéØ Farthest Point Sampling termin√© : {current_points:,} ‚Üí {len(pcd.points):,} points")

                                        # √âtape 4: Optimisation finale et validation
                                        final_points = len(pcd.points)
                                        processing_time = time.time() - start_time
                                        compression_ratio = n_points / final_points

                                        # M√©triques de qualit√©
                                        if final_points > 100:
                                            points_array = np.asarray(pcd.points)
                                            bbox_min = np.min(points_array, axis=0)
                                            bbox_max = np.max(points_array, axis=0)
                                            bbox_size = bbox_max - bbox_min

                                            # Calcul de la couverture spatiale
                                            volume = np.prod(bbox_size)
                                            spatial_coverage = final_points / volume if volume > 0 else 0

                                            st.success(f"‚úÖ Downsampling temps r√©el termin√© : {n_points:,} ‚Üí {final_points:,} points")
                                            st.info(f"‚ö° Performance : {processing_time:.3f}s ({final_points/processing_time:.0f} pts/s)")
                                            st.info(f"üìä M√©triques : Ratio {compression_ratio:.1f}x, Couverture {spatial_coverage:.2f} pts/unit√©¬≥")

                                            # Stockage des m√©triques pour l'interface
                                            st.session_state.realtime_downsampling_stats = {
                                                'original_points': n_points,
                                                'final_points': final_points,
                                                'processing_time_ms': processing_time * 1000,
                                                'compression_ratio': compression_ratio,
                                                'spatial_coverage': spatial_coverage,
                                                'strategy_used': strategy,
                                                'target_achieved': final_points >= target_points * 0.9  # 90% du target minimum
                                            }

                                        # √âtape 1: Analyse pr√©liminaire du bruit
                                        points_array = np.asarray(pcd_down.points)
                                        n_original = len(points_array)

                                        # Calcul des statistiques de base
                                        bbox = np.max(points_array, axis=0) - np.min(points_array, axis=0)
                                        volume = bbox[0] * bbox[1] * bbox[2]
                                        point_density = n_original / volume if volume > 0 else 0
                                        st.info(f"üìä Densit√© du nuage : {point_density:.2f} points/unit√©¬≥")

                                        # √âtape 2: Filtrage statistique avanc√© (Statistical Outlier Removal)
                                        if mesh_clean_artifacts:
                                            st.info("üßÆ Application du filtrage statistique avanc√©...")

                                            # Param√®tres adaptatifs selon la densit√©
                                            if point_density > 1000:  # Nuage tr√®s dense
                                                nb_neighbors_stat = 20
                                                std_ratio_stat = 1.5
                                            elif point_density > 100:  # Nuage dense
                                                nb_neighbors_stat = 30
                                                std_ratio_stat = 2.0
                                            else:  # Nuage sparse
                                                nb_neighbors_stat = 50
                                                std_ratio_stat = 2.5

                                            pcd_down, ind_stat = pcd_down.remove_statistical_outlier(
                                                nb_neighbors=nb_neighbors_stat,
                                                std_ratio=std_ratio_stat
                                            )
                                            st.info(f"üìà Filtrage statistique : {n_original} ‚Üí {len(pcd_down.points)} points (seuil: {std_ratio_stat}, voisins: {nb_neighbors_stat})")

                                        # √âtape 3: Filtrage par rayon (Radius Outlier Removal)
                                        st.info("üéØ Application du filtrage par rayon...")
                                        # Param√®tres moins agressifs pour √©viter la suppression excessive
                                        radius_min_points = 8 if point_density > 500 else 12 if point_density > 50 else 16
                                        adaptive_radius = mesh_voxel_size * 2  # Rayon moins large

                                        pcd_down, ind_radius = pcd_down.remove_radius_outlier(
                                            nb_points=radius_min_points,
                                            radius=adaptive_radius
                                        )
                                        st.info(f"üéØ Filtrage par rayon : {len(pcd_down.points)} points conserv√©s (rayon: {adaptive_radius:.4f}, min: {radius_min_points} voisins)")

                                        # √âtape 4: D√©bruitage conditionnel bas√© sur la densit√© locale
                                        if len(pcd_down.points) > 1000:
                                            st.info("üîç Analyse de densit√© locale pour d√©bruitage adaptatif...")

                                            # Calcul de la densit√© locale
                                            pcd_tree = o3d.geometry.KDTreeFlann(pcd_down)
                                            densities = []

                                            # √âchantillonnage pour performance
                                            sample_size = min(2000, len(pcd_down.points) // 10)
                                            sample_indices = np.random.choice(len(pcd_down.points), sample_size, replace=False)

                                            for idx in sample_indices:
                                                _, _, distances = pcd_tree.search_knn_vector_3d(pcd_down.points[idx], 20)
                                                if len(distances) > 1:
                                                    local_density = 1.0 / np.mean(distances[1:])**2
                                                    densities.append(local_density)

                                            if densities:
                                                densities = np.array(densities)
                                                density_threshold = np.percentile(densities, 10)  # 10√®me percentile

                                                # Identifier les r√©gions de faible densit√© (potentiellement bruit√©es)
                                                low_density_mask = []
                                                for i in range(len(pcd_down.points)):
                                                    _, _, distances = pcd_tree.search_knn_vector_3d(pcd_down.points[i], 20)
                                                    if len(distances) > 1:
                                                        local_density = 1.0 / np.mean(distances[1:])**2
                                                        low_density_mask.append(local_density < density_threshold)

                                                low_density_indices = np.where(low_density_mask)[0]
                                                if len(low_density_indices) > 0:
                                                    # Appliquer un filtrage plus strict aux r√©gions de faible densit√©
                                                    pcd_low_density = pcd_down.select_by_index(low_density_indices)
                                                    pcd_low_density, _ = pcd_low_density.remove_statistical_outlier(
                                                        nb_neighbors=10, std_ratio=1.0  # Plus strict
                                                    )

                                                    # Recombinaison des nuages
                                                    all_points = np.asarray(pcd_down.points)
                                                    low_density_points = np.asarray(pcd_low_density.points)
                                                    combined_points = np.vstack([all_points, low_density_points])
                                                    pcd_down.points = o3d.utility.Vector3dVector(combined_points)

                                                    st.info(f"üîß D√©bruitage conditionnel : {len(low_density_indices)} points de faible densit√© retrait√©s")

                                        # √âtape 5: Lissage adaptatif (Moving Least Squares)
                                        if mesh_smoothing_iterations > 0 and len(pcd_down.points) > 100:
                                            st.info("üåä Application du lissage Moving Least Squares...")

                                            # Param√®tres adaptatifs selon la qualit√©
                                            if mesh_quality_preset == "Ultra HD":
                                                search_radius = mesh_voxel_size * 2
                                                fitter_type = "polynomial"  # Plus pr√©cis mais plus lent
                                            elif mesh_quality_preset == "High":
                                                search_radius = mesh_voxel_size * 3
                                                fitter_type = "linear"
                                            else:  # Standard
                                                search_radius = mesh_voxel_size * 4
                                                fitter_type = "linear"

                                            try:
                                                # Essayer d'abord MLS polynomial si disponible
                                                pcd_down = pcd_down.filter_smooth_mls_polynomial(
                                                    polynomial_order=2 if fitter_type == "polynomial" else 1,
                                                    search_radius=search_radius,
                                                    num_threads=-1
                                                )
                                                st.info(f"üåä MLS polynomial smoothing appliqu√© (rayon: {search_radius:.4f}, ordre: {2 if fitter_type == 'polynomial' else 1})")
                                            except AttributeError:
                                                # Fallback vers simple smoothing si MLS n'est pas disponible
                                                try:
                                                    pcd_down = pcd_down.filter_smooth_simple(
                                                        number_of_iterations=mesh_smoothing_iterations,
                                                        filter_scope=2  # All neighbors
                                                    )
                                                    st.info(f"üåä Simple smoothing appliqu√© ({mesh_smoothing_iterations} it√©rations)")
                                                except Exception as e:
                                                    st.warning(f"‚ö†Ô∏è Smoothing non disponible: {e}")
                                            except Exception as e:
                                                st.warning(f"‚ö†Ô∏è MLS smoothing √©chou√©: {e} - utilisation du smoothing simple")
                                                try:
                                                    pcd_down = pcd_down.filter_smooth_simple(
                                                        number_of_iterations=mesh_smoothing_iterations,
                                                        filter_scope=2
                                                    )
                                                    st.info(f"üåä Fallback: Simple smoothing appliqu√© ({mesh_smoothing_iterations} it√©rations)")
                                                except Exception as e2:
                                                    st.warning(f"‚ö†Ô∏è Aucun smoothing disponible: {e2}")

                                        # √âtape 6: D√©bruitage des couleurs si disponibles
                                        if hasattr(pcd_down, 'colors') and len(pcd_down.colors) > 0:
                                            st.info("üé® D√©bruitage des couleurs...")

                                            # Filtrage bilat√©ral des couleurs
                                            colors_array = np.asarray(pcd_down.colors)

                                            # Calcul de la m√©diane locale pour chaque canal de couleur
                                            pcd_tree_colors = o3d.geometry.KDTreeFlann(pcd_down)
                                            filtered_colors = colors_array.copy()

                                            for i in range(len(colors_array)):
                                                _, idx, _ = pcd_tree_colors.search_knn_vector_3d(pcd_down.points[i], 15)
                                                if len(idx) > 1:
                                                    # M√©diane des couleurs voisines pour r√©duire le bruit
                                                    neighbor_colors = colors_array[idx[1:]]  # Exclure le point lui-m√™me
                                                    filtered_colors[i] = np.median(neighbor_colors, axis=0)

                                            pcd_down.colors = o3d.utility.Vector3dVector(filtered_colors)
                                            st.info("üé® Filtrage bilat√©ral des couleurs appliqu√©")

                                        # M√©triques finales du d√©bruitage
                                        n_final = len(pcd_down.points)
                                        noise_reduction = (n_original - n_final) / n_original * 100 if n_original > 0 else 0

                                        st.success(f"‚úÖ D√©bruitage industriel termin√© : {n_original} ‚Üí {n_final} points ({noise_reduction:.1f}% de bruit supprim√©)")

                                        # Stockage des m√©triques pour l'interface
                                        st.session_state.denoising_stats = {
                                            'original_points': n_original,
                                            'final_points': n_final,
                                            'noise_reduction_percent': noise_reduction,
                                            'statistical_filter_applied': mesh_clean_artifacts,
                                            'radius_filter_applied': True,
                                            'mls_smoothing_applied': mesh_smoothing_iterations > 0,
                                            'color_denoising_applied': hasattr(pcd_down, 'colors') and len(pcd_down.colors) > 0
                                        }

                                        # Estimation des normales avec param√®tres personnalis√©s
                                        pcd_down.estimate_normals(
                                            search_param=o3d.geometry.KDTreeSearchParamHybrid(
                                                radius=mesh_normal_radius, max_nn=mesh_normal_neighbors
                                            )
                                        )

                                        # Orientation coh√©rente avec it√©rations personnalis√©es
                                        pcd_down.orient_normals_consistent_tangent_plane(mesh_orientation_iterations)

                                        # Lissage pr√©-maillage personnalis√©
                                        if mesh_smoothing_iterations > 0:
                                            pcd_down = pcd_down.filter_smooth_taubin(number_of_iterations=mesh_smoothing_iterations)
                                    # Reconstruction conditionnelle avec param√®tres haute qualit√©
                                    if mesh_method == "Poisson":
                                        # Profondeur adaptative ou fixe selon le choix utilisateur
                                        if mesh_adaptive_depth:
                                            optimal_depth = min(14, max(8, int(np.log2(len(pcd_down.points) / 1000)) + 8))
                                            st.info(f"üåä Reconstruction Poisson adaptative : profondeur {optimal_depth}")
                                        else:
                                            optimal_depth = poisson_depth
                                            st.info(f"üåä Reconstruction Poisson fixe : profondeur {optimal_depth}")

                                        mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(
                                            pcd_down, depth=optimal_depth, width=0, scale=1.1, linear_fit=True
                                        )
                                    else:
                                        # Ball Pivoting avec rayons optimis√©s
                                        radii = [mesh_voxel_size * 2, mesh_voxel_size * 5, mesh_voxel_size * 10,
                                                mesh_voxel_size * 20, ball_pivoting_max_radius]
                                        st.info(f"‚öΩ Reconstruction Ball Pivoting : {len(radii)} rayons de {radii[0]:.4f} √† {radii[-1]:.4f}")

                                        mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_ball_pivoting(
                                            pcd_down, o3d.utility.DoubleVector(radii)
                                        )
                                        densities = None

                                    # Nettoyage avanc√© avec param√®tres de qualit√© adaptatifs
                                    if densities is not None and len(densities) > 0:
                                        # Seuil adaptatif bas√© sur la qualit√© s√©lectionn√©e
                                        if mesh_quality_preset == "Standard":
                                            quantile_low = np.quantile(densities, 0.05)  # Plus permissif
                                        elif mesh_quality_preset == "High":
                                            quantile_low = np.quantile(densities, 0.02)  # Moyen
                                        else:  # Ultra HD
                                            quantile_low = np.quantile(densities, 0.01)  # Tr√®s strict

                                        keep_mask = densities >= quantile_low
                                        mesh.remove_vertices_by_mask(~keep_mask)
                                        st.info(f"üßπ Nettoyage densit√© ({mesh_quality_preset}) : conserv√© {np.sum(keep_mask)}/{len(keep_mask)} vertices")

                                    # Post-traitement professionnel avec param√®tres adaptatifs
                                    mesh.remove_non_manifold_edges()
                                    mesh.remove_degenerate_triangles()
                                    mesh.remove_duplicated_triangles()
                                    mesh.remove_duplicated_vertices()
                                    mesh.remove_unreferenced_vertices()

                                    # Lissage adaptatif selon la qualit√©
                                    if mesh_smoothing_iterations > 0:
                                        if mesh_quality_preset == "Standard":
                                            smoothing_iters = min(mesh_smoothing_iterations, 2)
                                        elif mesh_quality_preset == "High":
                                            smoothing_iters = min(mesh_smoothing_iterations, 5)
                                        else:  # Ultra HD
                                            smoothing_iters = mesh_smoothing_iterations

                                        mesh = mesh.filter_smooth_taubin(number_of_iterations=smoothing_iters)
                                        st.info(f"üßº Lissage Taubin appliqu√© : {smoothing_iters} it√©rations")

                                    # Calcul des normales avec param√®tres avanc√©s
                                    mesh.compute_vertex_normals()

                                    # V√©rification qualit√© finale avec m√©triques d√©taill√©es
                                    n_vertices = len(mesh.vertices)
                                    n_triangles = len(mesh.triangles)

                                    # Calcul de m√©triques de qualit√©
                                    if len(mesh.triangles) > 0:
                                        triangle_areas = mesh.get_surface_area() / len(mesh.triangles)
                                        st.metric("üìê Surface moyenne par triangle", f"{triangle_areas:.6f} m¬≤")

                                    st.success(f"‚úÖ Maillage {mesh_quality_preset} g√©n√©r√© : {n_vertices} vertices, {n_triangles} triangles")

                                    # Calcul du volume si maillage ferm√©
                                    try:
                                        volume = mesh.get_volume()
                                        if volume > 0:
                                            st.metric("üìè Volume du maillage", f"{volume:.3f} m¬≥")
                                        else:
                                            st.warning("‚ö†Ô∏è Maillage partiellement ouvert ; ajoutez plus d'images pour une closure parfaite.")
                                    except:
                                        st.warning("‚ö†Ô∏è Impossible de calculer le volume (maillage ouvert)")

                                    # Lissage automatique des normales si activ√©
                                    if auto_smooth_normals:
                                        additional_smoothing = 5 if mesh_quality_preset == "Ultra HD" else 3
                                        mesh = mesh.filter_smooth_taubin(number_of_iterations=additional_smoothing)
                                        st.info(f"üîÑ Lissage automatique des normales : {additional_smoothing} it√©rations suppl√©mentaires")

                                    # Mapping UV basique si activ√©
                                    if basic_uv_mapping and len(mesh.vertices) > 0:
                                        mesh.compute_vertex_normals()  # Normaux pour projection UV
                                        st.info("üó∫Ô∏è Mapping UV basique appliqu√© (projection simple)")

                                    # Transfert de couleurs am√©lior√© avec param√®tres de qualit√©
                                    if len(mesh.vertices) > 0:
                                        pcd_tree = o3d.geometry.KDTreeFlann(pcd)
                                        vertices = np.asarray(mesh.vertices)
                                        colors = np.asarray(pcd.colors)

                                        # Nombre de voisins adaptatif selon la qualit√©
                                        k_neighbors = 10 if mesh_quality_preset == "Ultra HD" else 5
                                        mesh_colors = np.zeros((len(vertices), 3))

                                        for i in range(len(vertices)):
                                            _, idx, _ = pcd_tree.search_knn_vector_3d(vertices[i], k_neighbors)
                                            if len(idx) > 0:
                                                neighbor_colors = colors[idx]
                                                mesh_colors[i] = np.mean(neighbor_colors, axis=0)

                                        mesh.vertex_colors = o3d.utility.Vector3dVector(mesh_colors)
                                        st.info(f"üé® Couleurs transf√©r√©es ({k_neighbors} voisins pour {mesh_quality_preset})")

                                    # Lissage final des normales pour rendu professionnel
                                    mesh.compute_vertex_normals()
                                    
                                    # Lissage optionnel des vertex colors pour textures ultra-r√©alistes
                                    mesh.vertex_colors = o3d.utility.Vector3dVector(np.asarray(mesh.vertex_colors))
                                    
                                    # ============================================
                                    # VISUALISATION AVANC√âE DU MAILLAGE
                                    # ============================================
                                    
                                    # SUBDIVISION SURFACE (comme Blender)
                                    if subdivision_level > 0:
                                        st.info(f"üîÑ Application de subdivision niveau {subdivision_level}...")
                                        for _ in range(subdivision_level):
                                            mesh = mesh.subdivide_loop(number_of_iterations=1)
                                        mesh.compute_vertex_normals()
                                        st.success(f"‚úÖ Subdivision appliqu√©e: {len(mesh.vertices)} vertices, {len(mesh.triangles)} triangles")
                                    
                                    # AFFICHAGE DES INFORMATIONS TOPOLOGIQUES
                                    if show_topology_info:
                                        st.markdown("### üìä Analyse Topologique du Maillage")
                                        
                                        col_t1, col_t2, col_t3 = st.columns(3)
                                        
                                        with col_t1:
                                            st.metric("üî∫ Triangles", f"{len(mesh.triangles):,}")
                                            st.metric("üìç Vertices", f"{len(mesh.vertices):,}")
                                        
                                        with col_t2:
                                            # Calcul des edges
                                            edges = mesh.get_non_manifold_edges()
                                            st.metric("üìè Edges", f"{len(mesh.triangles) * 3 // 2:,}")
                                            st.metric("‚ö†Ô∏è Non-Manifold Edges", f"{len(edges)}")
                                        
                                        with col_t3:
                                            # Calcul de la densit√©
                                            bbox = mesh.get_axis_aligned_bounding_box()
                                            volume = bbox.volume()
                                            density = len(mesh.vertices) / volume if volume > 0 else 0
                                            st.metric("üì¶ Volume Bounding Box", f"{volume:.4f} m¬≥")
                                            st.metric("üéØ Densit√©", f"{density:.0f} pts/m¬≥")
                                        
                                        # Qualit√© des triangles
                                        triangles = np.asarray(mesh.triangles)
                                        vertices = np.asarray(mesh.vertices)
                                        
                                        if len(triangles) > 0:
                                            # Calcul de l'aire moyenne des triangles
                                            areas = []
                                            for tri in triangles[:1000]:  # √âchantillon pour performance
                                                v0, v1, v2 = vertices[tri]
                                                edge1 = v1 - v0
                                                edge2 = v2 - v0
                                                area = 0.5 * np.linalg.norm(np.cross(edge1, edge2))
                                                areas.append(area)
                                            
                                            st.write(f"**üìê Aire moyenne des triangles:** {np.mean(areas):.6f} m¬≤")
                                            st.write(f"**üìè Aire min/max:** {np.min(areas):.6f} / {np.max(areas):.6f} m¬≤")
                                    
                                    # G√âN√âRATION UV CHECKER PATTERN
                                    if show_uv_checker:
                                        st.info("üé® Application du checker pattern UV...")
                                        
                                        # Cr√©er une texture damier proc√©durale
                                        checker_size = 8
                                        checker_texture = np.zeros((len(mesh.vertices), 3))
                                        
                                        vertices = np.asarray(mesh.vertices)
                                        # Projection UV simple: utiliser X et Z pour UV
                                        uv_coords = vertices[:, [0, 2]]
                                        
                                        # Normaliser entre 0 et 1
                                        uv_min = uv_coords.min(axis=0)
                                        uv_max = uv_coords.max(axis=0)
                                        uv_range = uv_max - uv_min
                                        uv_range[uv_range == 0] = 1  # √âviter division par z√©ro
                                        uv_normalized = (uv_coords - uv_min) / uv_range
                                        
                                        # Appliquer damier
                                        for i in range(len(vertices)):
                                            u, v = uv_normalized[i]
                                            checker_u = int(u * checker_size) % 2
                                            checker_v = int(v * checker_size) % 2
                                            
                                            if checker_u == checker_v:
                                                checker_texture[i] = [0.9, 0.9, 0.9]  # Blanc
                                            else:
                                                checker_texture[i] = [0.1, 0.1, 0.1]  # Noir
                                        
                                        mesh.vertex_colors = o3d.utility.Vector3dVector(checker_texture)
                                        st.success("‚úÖ Checker pattern UV appliqu√©!")
                                    
                                    # Am√©lioration : Calcul et visualisation de la coque convexe pour mieux voir les limites
                                    geometries_to_draw = [mesh]
                                    
                                    # WIREFRAME OVERLAY
                                    if wireframe_overlay:
                                        st.info("üï∏Ô∏è G√©n√©ration du wireframe...")
                                        
                                        # Cr√©er un LineSet pour le wireframe
                                        lines = []
                                        triangles = np.asarray(mesh.triangles)
                                        
                                        for tri in triangles:
                                            # Ajouter les 3 ar√™tes du triangle
                                            lines.append([tri[0], tri[1]])
                                            lines.append([tri[1], tri[2]])
                                            lines.append([tri[2], tri[0]])
                                        
                                        # Supprimer les doublons
                                        lines = np.unique(np.sort(lines, axis=1), axis=0)
                                        
                                        wireframe = o3d.geometry.LineSet()
                                        wireframe.points = mesh.vertices
                                        wireframe.lines = o3d.utility.Vector2iVector(lines)
                                        
                                        # Couleur du wireframe
                                        wireframe_colors = [[0.0, 1.0, 0.0]] * len(lines)  # Vert fluo
                                        wireframe.colors = o3d.utility.Vector3dVector(wireframe_colors)
                                        
                                        geometries_to_draw.append(wireframe)
                                        st.success(f"‚úÖ Wireframe: {len(lines):,} edges")
                                    
                                    # VISUALISATION DES NORMALES
                                    if show_normals:
                                        st.info("‚û°Ô∏è G√©n√©ration des vecteurs normaux...")
                                        
                                        # Cr√©er des lignes pour les normales
                                        normals_vis = []
                                        vertices = np.asarray(mesh.vertices)
                                        normals = np.asarray(mesh.vertex_normals)
                                        
                                        # √âchantillonner pour performance (tous les 10 vertices)
                                        sample_rate = max(1, len(vertices) // 1000)
                                        
                                        normal_lines = []
                                        normal_points = []
                                        
                                        for i in range(0, len(vertices), sample_rate):
                                            start = vertices[i]
                                            end = start + normals[i] * normal_length
                                            
                                            point_idx = len(normal_points)
                                            normal_points.append(start)
                                            normal_points.append(end)
                                            normal_lines.append([point_idx, point_idx + 1])
                                        
                                        normal_lineset = o3d.geometry.LineSet()
                                        normal_lineset.points = o3d.utility.Vector3dVector(normal_points)
                                        normal_lineset.lines = o3d.utility.Vector2iVector(normal_lines)
                                        
                                        # Couleur cyan pour les normales
                                        normal_colors = [[0.0, 1.0, 1.0]] * len(normal_lines)
                                        normal_lineset.colors = o3d.utility.Vector3dVector(normal_colors)
                                        
                                        geometries_to_draw.append(normal_lineset)
                                        st.success(f"‚úÖ Normales: {len(normal_lines):,} vecteurs affich√©s")
                                    
                                    if show_hull and len(pcd.points) > 3:  # Au moins 4 points pour hull
                                        hull = pcd.compute_convex_hull()
                                        hull.paint_uniform_color([1.0, 0.0, 0.0])  # Rouge pour visibilit√©
                                        hull.compute_vertex_normals()
                                        geometries_to_draw.append(hull)
                                    
                                    # ============================================
                                    # FIN VISUALISATION AVANC√âE
                                    # ============================================
                                        st.info("Coque convexe ajout√©e en rouge pour d√©limiter la sc√®ne (volume int√©rieur maintenant coh√©rent avec maillage ferm√©).")
                                    
                                    # Visualisation avanc√©e du maillage HD avec coque si activ√©e
                                    o3d.visualization.draw_geometries(  # type: ignore
                                        geometries_to_draw,
                                        window_name=f"Maillage 3D {mesh_method} Ultra-R√©aliste HD avec Coque - {model_choice}",
                                        width=1600,
                                        height=900,
                                        mesh_show_back_face=True,  # Montre les faces arri√®re
                                        point_show_normal=False
                                    )
                                    
                                    # Cr√©ation du fichier temporaire pour le maillage (utilis√© pour download et Blender)
                                    mesh_tmp_path = os.path.join(tempfile.gettempdir(), f"temp_mesh_{uuid.uuid4().hex}.ply")
                                    success = o3d.io.write_triangle_mesh(mesh_tmp_path, mesh, write_vertex_colors=True, write_vertex_normals=True)  # Ajout flags pour export ferm√©
                                    if not success:
                                        st.error("Erreur lors de l'√©criture du fichier maillage.")
                                    else:
                                        time.sleep(0.2)  # Attente plus longue pour Windows
                                        if not os.path.exists(mesh_tmp_path):
                                            st.error("Fichier maillage temporaire non trouv√© apr√®s √©criture.")
                                        else:
                                            # Bouton de t√©l√©chargement pour le maillage (Windows-safe)
                                            with open(mesh_tmp_path, "rb") as f:
                                                mesh_bytes = f.read()
                                            st.download_button(
                                                label="üì• T√©l√©charger Maillage 3D (.ply)",
                                                data=mesh_bytes,
                                                file_name=f"{model_choice}_{mesh_method.lower()}_mesh.ply",
                                                mime="model/ply"
                                            )
                                    
                                    # Nouvelle fonctionnalit√© 1: Export OBJ si activ√©
                                    if export_obj:
                                        obj_tmp_path = os.path.join(tempfile.gettempdir(), f"temp_obj_{uuid.uuid4().hex}.obj")
                                        o3d.io.write_triangle_mesh(obj_tmp_path, mesh, write_ascii=True, compressed=False)
                                        time.sleep(0.1)
                                        if os.path.exists(obj_tmp_path):
                                            with open(obj_tmp_path, "rb") as f:
                                                obj_bytes = f.read()
                                            st.download_button(
                                                label="üì• T√©l√©charger Maillage 3D (.obj + .mtl)",
                                                data=obj_bytes,
                                                file_name=f"{model_choice}_{mesh_method.lower()}_mesh.obj",
                                                mime="model/obj"
                                            )
                                            os.remove(obj_tmp_path)
                                    
                                    st.info("üí° Pour un rendu encore plus r√©aliste, exporte le maillage vers Blender/Unreal Engine en utilisant `mesh.export('mesh.ply')`.")

                                    # Rendu avanc√© avec Blender si activ√© (avec check installation)
                                    if advanced_blender and success and os.path.exists(mesh_tmp_path):
                                        if shutil.which('blender') is None:
                                            st.warning("‚ö†Ô∏è Blender non trouv√© dans le PATH ; installez-le pour activer le rendu avanc√©.")
                                        else:
                                            st.info("üîÑ Lancement du rendu avanc√© avec Blender...")
                                            render_tmp_path = None
                                            script_tmp_path = None
                                            blend_tmp_path = None
                                            try:
                                                render_tmp_path = os.path.join(tempfile.gettempdir(), f"temp_render_{uuid.uuid4().hex}.png")
                                                script_tmp_path = os.path.join(tempfile.gettempdir(), f"temp_script_{uuid.uuid4().hex}.py")
                                                if save_blend_file:
                                                    blend_tmp_path = os.path.join(tempfile.gettempdir(), f"temp_blend_{uuid.uuid4().hex}.blend")
                                                script_content = f"""
import bpy
from math import pi
import os

# V√©rification du fichier maillage
if not os.path.exists(r'{mesh_tmp_path}'):
    print("Erreur: Fichier maillage non trouv√©: {mesh_tmp_path}")
else:
    print("Fichier maillage trouv√©.")

# Clear scene
bpy.ops.wm.read_factory_settings(use_empty=True)

# Import mesh
bpy.ops.import_mesh.ply(filepath=r'{mesh_tmp_path}')

# Get the mesh object and apply material for vertex colors
mesh_obj = None
for obj in bpy.data.objects:
    if obj.type == 'MESH':
        mesh_obj = obj
        bpy.context.view_layer.objects.active = obj
        # Create material
        mat = bpy.data.materials.new(name="VertexColorMaterial")
        mat.use_nodes = True
        obj.data.materials.append(mat)
        # Clear default nodes
        nodes = mat.node_tree.nodes
        nodes.clear()
        # Add nodes
        output = nodes.new(type='ShaderNodeOutputMaterial')
        principled = nodes.new(type='ShaderNodeBsdfPrincipled')
        attribute = nodes.new(type='ShaderNodeAttribute')
        # Set attribute
        attribute.attribute_name = "Col"
        # Link nodes
        mat.node_tree.links.new(attribute.outputs['Color'], principled.inputs['Base Color'])
        mat.node_tree.links.new(principled.outputs['BSDF'], output.inputs['Surface'])
        # Position nodes
        output.location = (400, 0)
        principled.location = (0, 0)
        attribute.location = (-200, 0)
        break

if mesh_obj is not None:
    # Rotate object
    mesh_obj.rotation_euler[0] = pi / 2
    mesh_obj.rotation_euler[2] = -3 * pi / 4

    # Camera setup
    cam = bpy.data.objects['Camera']
    cam.location.x = -0.05
    cam.location.y = -1.2
    cam.location.z = 0.52
    cam.rotation_euler[0] = 1.13446
    cam.rotation_euler[1] = 0
    cam.rotation_euler[2] = 0

    # Add light
    light_data = bpy.data.lights.new(name="Sun", type='SUN')
    light_data.energy = 5
    light_obj = bpy.data.objects.new(name="Sun", object_data=light_data)
    bpy.context.collection.objects.link(light_obj)
    light_obj.location = (5, 5, 5)

    # Render settings
    bpy.context.scene.render.engine = 'CYCLES'
    bpy.context.scene.render.image_settings.color_mode = 'RGBA'
    bpy.context.scene.render.filepath = r'{render_tmp_path}'
    bpy.ops.render.render(write_still=True)

    # Nouvelle fonctionnalit√© 3: Vues multiples si activ√©
    if {multi_view_blender}:
        # Vue frontale
        cam.location = (0, -2, 0)
        cam.rotation_euler = (pi/2, 0, 0)
        bpy.context.scene.render.filepath = r'{render_tmp_path.replace('.png', '_front.png')}'
        bpy.ops.render.render(write_still=True)
        
        # Vue lat√©rale
        cam.location = (2, 0, 0)
        cam.rotation_euler = (pi/2, 0, pi/2)
        bpy.context.scene.render.filepath = r'{render_tmp_path.replace('.png', '_side.png')}'
        bpy.ops.render.render(write_still=True)
        
        # Vue sup√©rieure
        cam.location = (0, 0, 2)
        cam.rotation_euler = (0, 0, 0)
        bpy.context.scene.render.filepath = r'{render_tmp_path.replace('.png', '_top.png')}'
        bpy.ops.render.render(write_still=True)

    # Nouvelle fonctionnalit√© 5: Sauvegarde .blend si activ√©
    if {save_blend_file}:
        bpy.ops.wm.save_as_mainfile(filepath=r'{blend_tmp_path}')
"""
                                                with open(script_tmp_path, 'w') as script_file:
                                                    script_file.write(script_content)

                                                # Run Blender
                                                result = subprocess.run(["blender", "--background", "--python", script_tmp_path], capture_output=True, text=True)
                                                if result.returncode == 0:
                                                    st.success("Rendu Blender termin√© avec succ√®s !")
                                                    if os.path.exists(render_tmp_path):
                                                        st.image(render_tmp_path, caption="Rendu Avanc√© Blender", use_container_width=True)
                                                        # Download button for render
                                                        with open(render_tmp_path, "rb") as f:
                                                            render_bytes = f.read()
                                                        st.download_button(
                                                            label="üì• T√©l√©charger Rendu Blender (.png)",
                                                            data=render_bytes,
                                                            file_name=f"{model_choice}_{mesh_method.lower()}_blender_render.png",
                                                            mime="image/png"
                                                        )
                                                    
                                                    # T√©l√©chargements pour vues multiples
                                                    if multi_view_blender:
                                                        front_path = render_tmp_path.replace('.png', '_front.png')
                                                        side_path = render_tmp_path.replace('.png', '_side.png')
                                                        top_path = render_tmp_path.replace('.png', '_top.png')
                                                        if os.path.exists(front_path):
                                                            with open(front_path, "rb") as f:
                                                                front_bytes = f.read()
                                                            st.download_button(
                                                                label="üì• Vue Frontale (.png)",
                                                                data=front_bytes,
                                                                file_name=f"{model_choice}_{mesh_method.lower()}_front.png",
                                                                mime="image/png"
                                                            )
                                                        if os.path.exists(side_path):
                                                            with open(side_path, "rb") as f:
                                                                side_bytes = f.read()
                                                            st.download_button(
                                                                label="üì• Vue Lat√©rale (.png)",
                                                                data=side_bytes,
                                                                file_name=f"{model_choice}_{mesh_method.lower()}_side.png",
                                                                mime="image/png"
                                                            )
                                                        if os.path.exists(top_path):
                                                            with open(top_path, "rb") as f:
                                                                top_bytes = f.read()
                                                            st.download_button(
                                                                label="üì• Vue Sup√©rieure (.png)",
                                                                data=top_bytes,
                                                                file_name=f"{model_choice}_{mesh_method.lower()}_top.png",
                                                                mime="image/png"
                                                            )
                                                    
                                                    # T√©l√©chargement .blend si activ√©
                                                    if save_blend_file and blend_tmp_path and os.path.exists(blend_tmp_path):
                                                        with open(blend_tmp_path, "rb") as f:
                                                            blend_bytes = f.read()
                                                        st.download_button(
                                                            label="üì• Sc√®ne Blender (.blend)",
                                                            data=blend_bytes,
                                                            file_name=f"{model_choice}_{mesh_method.lower()}_scene.blend",
                                                            mime="application/x-blender"
                                                        )
                                                else:
                                                    st.error(f"Erreur Blender : {result.stderr}")
                                            finally:
                                                if render_tmp_path and os.path.exists(render_tmp_path):
                                                    os.unlink(render_tmp_path)
                                                if script_tmp_path and os.path.exists(script_tmp_path):
                                                    os.unlink(script_tmp_path)
                                                if blend_tmp_path and os.path.exists(blend_tmp_path):
                                                    os.unlink(blend_tmp_path)
                                    
                                    # Nettoyage final du fichier maillage temporaire seulement si pas utilis√© par Blender ou apr√®s
                                    if os.path.exists(mesh_tmp_path):
                                        os.remove(mesh_tmp_path)
                                    
                                    
                            except Exception as mesh_error:
                                st.error(f"Erreur lors de la g√©n√©ration du maillage : {mesh_error}")
                                st.info("V√©rifiez la densit√© des points ; essayez un downsampling plus fort ou une profondeur Poisson plus faible.")
                    else:
                        st.warning("Aucun point valide trouv√© apr√®s filtrage.")
                   
                    # Visualisation du nuage de points 3D avec Plotly (couleur par Z pour simplicit√©)
                    st.header("‚òÅÔ∏è Nuage de Points 3D (Plotly)")
                    if len(merged_pts3d) > 0:
                        fig = go.Figure(data=[go.Scatter3d(
                            x=merged_pts3d[:, 0],
                            y=merged_pts3d[:, 1],
                            z=merged_pts3d[:, 2],
                            mode='markers',
                            marker=dict(
                                size=2,
                                color=merged_pts3d[:, 2],  # Couleur par Z pour profondeur
                                colorscale='Viridis',
                                showscale=True,
                                colorbar=dict(title="Profondeur (Z) ajust√©e")
                            )
                        )])
                        fig.update_layout(
                            title=f"Reconstruction 3D Globale avec {model_choice} (Vue Simplifi√©e)",
                            scene=dict(
                                xaxis_title="X",
                                yaxis_title="Y",
                                zaxis_title="Z",
                                aspectmode='data'
                            ),
                            width=800,
                            height=600
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.warning("Aucun point √† afficher dans Plotly.")
                   
                    # Aper√ßu des images originales
                    st.header("üñºÔ∏è Aper√ßu des Images")
                    cols = st.columns(len(uploaded_files))
                    for i, uploaded_file in enumerate(uploaded_files):
                        cols[i].image(uploaded_file, caption=f"Image {i+1}", use_container_width=True)
                   
                    # Statistiques (ajout temps traitement)
                    st.header("üìä Statistiques")
                    col_stats1, col_stats2, col_stats3 = st.columns(3)
                    with col_stats1:
                        st.metric("Nombre de points 3D", f"{len(merged_pts3d):,}")
                        st.metric("Nombre d'images", len(uploaded_files))
                    with col_stats2:
                        st.metric("Paires trait√©es", num_pairs)
                        st.metric("Perte d'alignement", f"{loss_value:.4f}")
                    with col_stats3:
                        processing_time = time.time() - start_time
                        st.metric("Temps de traitement", f"{processing_time:.1f}s")
               
                except Exception as e:
                    st.error(f"Erreur lors du traitement : {e}")
                    st.info("V√©rifiez que les images sont valides et que le GPU a assez de m√©moire.")
    else:
        st.info("‚ö†Ô∏è Chargez au moins 2 images et cliquez sur 'Lancer la Reconstruction 3D' pour commencer.")

# Footer
st.markdown("---")
st.markdown("**D√©velopp√© avec ‚ù§Ô∏è en utilisant DUSt3R de Naver Labs et MapAnything de Facebook Research. Assurez-vous d'avoir CUDA 12.1+ pour une performance optimale.**")

# Instructions d'installation (affich√©es en sidebar)
with st.sidebar:
    st.header("üõ†Ô∏è Installation Requise")
    model_choice_placeholder = st.radio("S√©lectionnez pour voir les instructions :", ["DUSt3R"], key="install_choice")
    if model_choice_placeholder == "DUSt3R":
        st.code("""
pip install git+https://github.com/naver/dust3r.git
pip install streamlit plotly pillow numpy torch torchvision open3d scikit-learn transformers faiss-cpu pandas psutil pynvml  # FAISS optionnel (fallback sklearn) ; psutil/pynvml pour monitoring
# Pour Blender : T√©l√©chargez depuis blender.org et ajoutez au PATH
# Pour scalabilit√© >10 images : pip install pycolmap (optionnel)
        """)
    st.markdown("**Lancer l'app :** `streamlit run app.py`")
    if st.button("üîó Lien GitHub DUSt3R"):
        st.markdown("[https://github.com/naver/dust3r](https://github.com/naver/dust3r)")