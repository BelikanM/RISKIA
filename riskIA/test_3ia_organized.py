#!/usr/bin/env python3
"""
Test script pour l'analyse organis√©e avec 3 IA sp√©cialis√©es :
- CLIP : Environnement, sol, datation
- Florence : B√¢timents, toitures, dangers
- GLM : Synth√®se globale
"""

import os
import sys
import torch
from PIL import Image
from transformers import CLIPProcessor, CLIPModel, AutoProcessor, AutoModelForCausalLM, AutoTokenizer
import warnings
warnings.filterwarnings("ignore")

# Configuration des chemins
os.environ['HF_HOME'] = r'C:\Users\Admin\Desktop\logiciel\riskIA\models'
os.environ['TRANSFORMERS_CACHE'] = r'C:\Users\Admin\Desktop\logiciel\riskIA\models'

def test_clip_analysis(image_path):
    """Test CLIP pour environnement, sol, datation"""
    print("üîÑ Test CLIP : Chargement du mod√®le...")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Device: {device}")

    try:
        # Utiliser le mod√®le local
        clip_path = r"C:\Users\Admin\Desktop\logiciel\riskIA\models\models--openai--clip-vit-base-patch32"
        model = CLIPModel.from_pretrained(clip_path).to(device)
        processor = CLIPProcessor.from_pretrained(clip_path)

        print("üì∏ Analyse environnementale...")
        image = Image.open(image_path).convert('RGB')

        # Prompts sp√©cialis√©s pour l'environnement et le sol
        environment_prompts = [
            # Environnement g√©n√©ral
            "environnement naturel pr√©serv√© sans pollution visible",
            "environnement urbain avec b√¢timents et infrastructures",
            "environnement industriel avec √©quipements lourds",
            "environnement c√¥tier ou maritime",
            "environnement forestier ou v√©g√©tal dense",
            "environnement d√©sertique ou aride",

            # Texture du sol
            "sol sableux ou granulaire fin",
            "sol argileux ou collant",
            "sol rocheux ou pierreux",
            "sol limoneux ou interm√©diaire",
            "sol tourbeux ou organique",
            "sol instable ou √©rod√©",

            # Datation environnementale
            "site r√©cent avec constructions modernes",
            "site ancien avec signes d'usure naturelle",
            "site historique avec pr√©servation patrimoniale",
            "site en d√©veloppement actif",
            "site abandonn√© avec v√©g√©tation envahissante",
            "site en r√©novation ou maintenance",

            # Conditions m√©t√©orologiques
            "conditions s√®ches et stables",
            "conditions humides avec pluie r√©cente",
            "conditions venteuses avec signes d'√©rosion √©olienne",
            "conditions extr√™mes avec dommages visibles"
        ]

        inputs = processor(text=environment_prompts, images=image, return_tensors="pt", padding=True, truncation=True).to(device)
        with torch.no_grad():
            outputs = model(**inputs)
        probs = outputs.logits_per_image.softmax(dim=1)[0]

        clip_results = [(label, score.item()) for label, score in zip(environment_prompts, probs) if score > 0.03]
        clip_results.sort(key=lambda x: x[1], reverse=True)

        print("‚úÖ CLIP r√©ussi !")
        print("Top 5 r√©sultats CLIP :")
        for i, (label, score) in enumerate(clip_results[:5]):
            print(".3f")

        return clip_results

    except Exception as e:
        print(f"‚ùå Erreur CLIP: {str(e)}")
        return []

def test_florence_analysis(image_path):
    """Test Florence pour b√¢timents, toitures, dangers"""
    print("\nüîÑ Test Florence : Chargement du mod√®le...")

    try:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        # Utiliser le mod√®le local
        florence_path = r"C:\Users\Admin\Desktop\logiciel\riskIA\models\models--microsoft--Florence-2-base-ft"
        processor = AutoProcessor.from_pretrained(florence_path, trust_remote_code=True)
        model = AutoModelForCausalLM.from_pretrained(florence_path, trust_remote_code=True).to(device)

        print("üèóÔ∏è Analyse architecturale...")
        image = Image.open(image_path).convert('RGB')

        # T√¢ches Florence pour analyse d√©taill√©e
        florence_tasks = [
            "<CAPTION_TO_PHRASE_GROUNDING> Locate and describe buildings and their roofs",
            "<DETAILED_CAPTION> Describe building conditions, roof materials, and structural integrity",
            "<CAPTION_TO_PHRASE_GROUNDING> Identify roofing materials and textures",
            "<DETAILED_CAPTION> Analyze building age, construction quality, and potential hazards",
            "<CAPTION_TO_PHRASE_GROUNDING> Detect structural damages, cracks, or deterioration",
            "<MORE_DETAILED_CAPTION> Assess building safety and risk factors"
        ]

        florence_results = []
        for task in florence_tasks:
            try:
                inputs = processor(text=task, images=image, return_tensors="pt").to(device)
                with torch.no_grad():
                    generated_ids = model.generate(**inputs, max_new_tokens=100, do_sample=False)
                result = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
                florence_results.append((task, result))
                print(f"  ‚úì {task}: {result[:80]}...")
            except Exception as e:
                florence_results.append((task, f"Erreur: {str(e)}"))
                print(f"  ‚ùå {task}: Erreur - {str(e)}")

        print("‚úÖ Florence r√©ussi !")
        return florence_results

    except Exception as e:
        print(f"‚ùå Erreur Florence: {str(e)}")
        return []

def test_glm_synthesis(clip_results, florence_results):
    """Test GLM pour synth√®se globale"""
    print("\nüîÑ Test GLM : Chargement du mod√®le...")

    try:
        # Essayer diff√©rents chemins GLM locaux uniquement
        glm_paths = [
            r"C:\Users\Admin\Desktop\logiciel\riskIA\models\glm-4v-9b"
        ]

        glm_model = None
        glm_tokenizer = None

        for path in glm_paths:
            try:
                print(f"  Tentative avec: {path}")
                glm_tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True)
                glm_model = AutoModelForCausalLM.from_pretrained(path, torch_dtype=torch.float16, device_map="auto", trust_remote_code=True)
                print(f"  ‚úÖ GLM charg√© depuis: {path}")
                break
            except Exception as e:
                print(f"  ‚ùå √âchec avec {path}: {str(e)}")
                continue

        if glm_model is None:
            print("‚ùå Aucun mod√®le GLM trouv√©. Test de synth√®se simul√©.")
            synthesis = "SYNTH√àSE SIMUL√âE : Analyse bas√©e sur CLIP et Florence uniquement.\n\n"
            synthesis += "R√âSULTATS CLIP (Environnement/Sol/Datation) :\n"
            for label, score in clip_results[:3]:
                synthesis += f"- {label}: {score:.3f}\n"
            synthesis += "\n\nR√âSULTATS FLORENCE (B√¢timents/Dangers) :\n"
            for task, result in florence_results:
                synthesis += f"- {task}: {result[:100]}...\n"
            synthesis += "\nCONCLUSION : Analyse multi-modale r√©ussie !"
            return synthesis

        # Prompt de synth√®se int√©grant les r√©sultats des autres IA
        synthesis_prompt = f"""
        Analyse int√©gr√©e des risques bas√©e sur 3 IA sp√©cialis√©es :

        ANALYSE CLIP (Environnement/Sol/Datation) :
        {chr(10).join([f"- {label}: {score:.3f}" for label, score in clip_results[:5]])}

        ANALYSE FLORENCE (B√¢timents/Toitures/Dangers) :
        {chr(10).join([f"- {task}: {result}" for task, result in florence_results])}

        SYNTH√àSE REQUISE :
        1. √âvaluation globale des risques environnementaux et structurels
        2. Datation estim√©e du site et des b√¢timents
        3. Dangers prioritaires identifi√©s
        4. Mesures correctives recommand√©es
        5. Niveau de criticit√© (Faible/Mod√©r√©/√âlev√©/Critique)

        Fournir une analyse professionnelle structur√©e.
        """

        inputs = glm_tokenizer(synthesis_prompt, return_tensors="pt").to(glm_model.device)
        outputs = glm_model.generate(**inputs, max_new_tokens=500, temperature=0.3, do_sample=True)
        synthesis = glm_tokenizer.decode(outputs[0], skip_special_tokens=True)

        print("‚úÖ GLM r√©ussi !")
        print(f"Synth√®se GLM ({len(synthesis)} caract√®res)")
        return synthesis

    except Exception as e:
        print(f"‚ùå Erreur GLM: {str(e)}")
        return f"Erreur GLM: {str(e)}"

def main():
    """Fonction principale de test"""
    print("üß† TEST D'ANALYSE ORGANIS√âE AVEC 3 IA SP√âCIALIS√âES")
    print("=" * 60)

    # Trouver une image de test
    test_images = [
        r"C:\Users\Admin\Desktop\logiciel\riskIA\croquis_site_gabon.png",
        r"C:\Users\Admin\Desktop\logiciel\riskIA\annotated_scientific_gabon.png",
        r"C:\Users\Admin\Desktop\logiciel\riskIA\cap.png"
    ]

    image_path = None
    for img in test_images:
        if os.path.exists(img):
            image_path = img
            break

    if not image_path:
        print("‚ùå Aucune image de test trouv√©e !")
        return

    print(f"üì∑ Image de test: {image_path}")

    # Test CLIP
    clip_results = test_clip_analysis(image_path)

    # Test Florence
    florence_results = test_florence_analysis(image_path)

    # Test GLM
    glm_synthesis = test_glm_synthesis(clip_results, florence_results)

    # R√©sum√© final
    print("\n" + "=" * 60)
    print("üìä R√âSULTATS FINAUX")
    print("=" * 60)

    print(f"\nüîç CLIP : {len(clip_results)} √©l√©ments environnementaux d√©tect√©s")
    print(f"üèóÔ∏è Florence : {len(florence_results)} analyses architecturales r√©alis√©es")
    print(f"üß† GLM : Synth√®se de {len(glm_synthesis)} caract√®res g√©n√©r√©e")

    print("\n‚úÖ TEST R√âUSSI !" if clip_results and florence_results else "‚ùå TEST √âCHOU√â !")

    # Sauvegarder les r√©sultats
    with open("test_3ia_results.txt", "w", encoding="utf-8") as f:
        f.write("R√âSULTATS TEST 3 IA ORGANIS√âES\n")
        f.write("=" * 50 + "\n\n")
        f.write("CLIP RESULTS:\n")
        for label, score in clip_results[:10]:
            f.write(".3f")
        f.write("\n\nFLORENCE RESULTS:\n")
        for task, result in florence_results:
            f.write(f"- {task}: {result}\n")
        f.write(f"\n\nGLM SYNTHESIS:\n{glm_synthesis}")

    print("\nüíæ R√©sultats sauvegard√©s dans 'test_3ia_results.txt'")

if __name__ == "__main__":
    main()