#!/usr/bin/env python3
"""
Test final de l'analyse de textures avec toutes les corrections
"""
import sys
import os
import subprocess

# Configuration de l'environnement portable
script_dir = os.path.dirname(os.path.abspath(__file__))
lib_dir = os.path.join(script_dir, 'Lib')
site_packages_dir = os.path.join(lib_dir, 'site-packages')
python_exe = os.path.join(script_dir, 'python.exe')

print("=== Test final de l'analyse de textures ===")
print(f"Environnement portable: {script_dir}")
print()

# Test avec subprocess isol√©
env = os.environ.copy()
env['PYTHONPATH'] = f"{lib_dir};{site_packages_dir};{script_dir}"
env['PYTHONHOME'] = script_dir
env['PYTHONNOUSERSITE'] = '1'
env['HF_HOME'] = os.path.join(script_dir, 'models')
env['TRANSFORMERS_CACHE'] = os.path.join(script_dir, 'models')

test_code = '''
import sys
import os

# Simuler les variables d√©finies dans l'application
script_dir = r"''' + script_dir.replace('\\', '\\\\') + '''"
models_dir = os.path.join(script_dir, 'models')
os.environ['HF_HOME'] = models_dir
os.environ['TRANSFORMERS_CACHE'] = models_dir

print("=== Simulation de run_texture_analysis ===")

try:
    import torch
    from transformers import CLIPProcessor, CLIPModel
    from PIL import Image
    import numpy as np

    print("‚úÖ Imports r√©ussis")

    # Simuler le chargement des mod√®les comme dans l'application
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model_path = os.path.join(script_dir, "models", "hub", "models--openai--clip-vit-base-patch32")
    kibali_path = os.path.join(script_dir, "models", "kibali-final-merged")

    print(f"Device: {device}")
    print(f"CLIP path: {model_path}")
    print(f"Kibali path: {kibali_path}")
    print(f"CLIP exists: {os.path.exists(model_path)}")
    print(f"Kibali exists: {os.path.exists(kibali_path)}")

    # Charger CLIP
    clip_model = CLIPModel.from_pretrained(model_path).to(device)
    clip_processor = CLIPProcessor.from_pretrained(model_path)
    print("‚úÖ CLIP charg√©")

    # Simuler une image comme dans l'application
    dummy_image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
    pil_image = Image.fromarray(dummy_image.astype('uint8'), 'RGB')
    print("‚úÖ Image PIL cr√©√©e")

    # Traiter l'image (comme corrig√© dans l'application)
    inputs = clip_processor(images=pil_image, return_tensors="pt").to(device)
    print("‚úÖ Image trait√©e par CLIP")

    # Labels de test
    texture_labels = ["corroded metal surface", "rusted steel structure", "burnt vegetation"]

    # Encoder les labels
    text_inputs = clip_processor(text=texture_labels, return_tensors="pt", padding=True).to(device)
    print("‚úÖ Labels encod√©s")

    # Calculer les similarit√©s
    with torch.no_grad():
        image_features = clip_model.get_image_features(**inputs)
        text_features = clip_model.get_text_features(**text_inputs)

        # Normaliser
        image_features = image_features / image_features.norm(dim=-1, keepdim=True)
        text_features = text_features / text_features.norm(dim=-1, keepdim=True)

        # Calculer les similarit√©s
        similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)

    # R√©sultats
    probs = similarity[0].cpu().numpy()
    detected_textures = [(texture_labels[i], float(probs[i])) for i in range(len(texture_labels))]
    detected_textures.sort(key=lambda x: x[1], reverse=True)

    print("‚úÖ Analyse de textures r√©ussie!")
    print(f"R√©sultats: {detected_textures[:3]}")

    # Test Kibali si disponible
    try:
        from transformers import AutoModelForCausalLM, AutoTokenizer
        kibali_model = AutoModelForCausalLM.from_pretrained(kibali_path)
        kibali_tokenizer = AutoTokenizer.from_pretrained(kibali_path)
        print("‚úÖ Kibali disponible")

        # Test rapide de g√©n√©ration
        prompt = "Test Kibali"
        inputs = kibali_tokenizer(prompt, return_tensors="pt", max_length=50, truncation=True)
        with torch.no_grad():
            outputs = kibali_model.generate(**inputs, max_new_tokens=10, do_sample=False)
        response = kibali_tokenizer.decode(outputs[0], skip_special_tokens=True)
        print(f"‚úÖ Kibali g√©n√©ration: {response[:50]}...")

    except Exception as e:
        print(f"‚ö†Ô∏è Kibali non disponible: {e}")

except Exception as e:
    print(f"‚ùå Erreur: {e}")
    import traceback
    traceback.print_exc()
'''

try:
    result = subprocess.run([python_exe, '-c', test_code],
                          cwd=script_dir,
                          env=env,
                          capture_output=True,
                          text=True,
                          timeout=120)

    print("=== R√âSULTATS DU TEST ===")
    print(result.stdout)
    if result.stderr:
        print("=== ERREURS ===")
        print(result.stderr)
    print(f"=== CODE RETOUR: {result.returncode} ===")

    if result.returncode == 0 and "Analyse de textures r√©ussie!" in result.stdout:
        print("\nüéâ SUCC√àS ! L'analyse de textures fonctionne maintenant !")
    else:
        print("\n‚ùå √âCHEC ! Il y a encore des probl√®mes.")

except Exception as e:
    print(f"Erreur subprocess: {e}")